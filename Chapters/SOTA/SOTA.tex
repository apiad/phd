\chapter{Estado del Arte}\label{Chapter:SOTA}
\markboth{\MakeUppercase{Estado del Arte}}{}

Intro del estado del arte

- el descubrimiento de conocimiento en lenguaje natural

Los humanos consumen la información ambiental y la transforman en conceptos independientes, que pueden relacionarse entre sí.
En general, solo almacenamos una pequeña parte de toda la información que procesamos todos los días.
Esta información consta de los conceptos y relaciones más importantes, que pueden ser útiles en situaciones futuras.
Así, aprendemos básicamente separando lo que podría considerarse ruido de la información que pensamos que será útil en el futuro.
En general, dijimos dos tipos de recuerdos: uno para el conocimiento reciente y otro donde almacenamos el conocimiento durante mucho tiempo.

Hoy en día, una de las mayores fuentes de información de Internet
es texto en lenguaje natural, que aparece en noticias, opiniones, mensajes, enciclopedias y muchas otras formas de comunicación digital.
Esto no es accidental, ya que las palabras~(representadas computacionalmente como texto) son uno de los canales de comunicación más importantes a lo largo de la historia de la humanidad.
Uno de los conceptos más básicos reconocibles en el lenguaje natural que brindan información útil son las acciones. Por lo general, se asocian con dos conceptos distintivos, el sujeto y el objetivo. El primero es quién realiza la acción, y el segundo es quién recibe las consecuencias de dicha acción.
Identificar correctamente las acciones, sus correspondientes sujetos y destinatarios es uno de los retos más básicos y fundamentales para comprender la información.

El crecimiento acelerado de Internet ha producido un excedente de información (noticias, correo electrónico, redes sociales, blogs) que supera con creces nuestra capacidad de procesamiento y consumo de datos.
Así, la construcción de sistemas automáticos que puedan extraer conocimiento de este flujo de información se ha convertido en uno de los campos de investigación más activos en la informática. Este fenómeno ha sido
denominado Big Data~\cite{bigdata}, y su estudio ha atraído la atención de diferentes comunidades de investigación como inteligencia empresarial~\cite{chen2012business}, ingeniería que incluye física y biológica~\cite{wu2014data} y redes sociales~\cite{shah2015big}.

- importancia de la semántica

% PAPER ICAII

Los seres humanos intentan representar el mundo en el que vivimos y los hechos y eventos que suceden usando el lenguaje. El lenguaje permite estructurar las ideas para que puedan compartirse con otras personas.
Generalmente, una de las formas más comunes de representar piezas arbitrarias de conocimiento es a través de la noción de conceptos y acciones~\cite{teleologies}.
Al comprender el mundo como compuesto de conceptos que interactúan entre sí a través de acciones, los humanos pueden comunicar una gran variedad y complejidad de información y conocimiento.
La forma más sencilla de combinar conceptos y acciones es a través de relaciones binarias, donde un concepto actúa como sujeto y otro como objetivo.
Esta estructura simple es muy común en los lenguajes humanos.
Más del 75 \% de los idiomas tienen una estructura sintáctica que sigue el orden SVO (sujeto-verbo-objeto) o SOV (sujeto-objeto-verbo~\cite{cambridge}.
Además, Sujeto-Verbo-Objeto es el orden más común en las lenguas criollas, lo que se ha sugerido como una indicación de que es el orden más natural.
para la psicología humana.~\cite{diamond2013rise}.
Como ejemplo, de la oración `` Arnold conduce un automóvil '' y obtenemos un triplete Sujeto-Verbo-Objeto \verb|(Arnold, conduce, automóvil)|.

Esta estructura es omnipresente en muchos problemas diferentes en el campo del procesamiento del lenguaje natural.
Diferentes autores han empleado un Sujeto-Verbo-Objeto para una estructura similar o para representar conocimiento extraído de un texto natural, en una variedad de dominios~\cite{mitchell2015never,Balahur2011}.
Así, una representación basada en el triplete Sujeto-Verbo-Objeto es adecuada para la representación genérica del conocimiento, independientemente del dominio.

Las ontologías son una de las representaciones más comunes del conocimiento en formato digital.
Las ontologías, las bases de conocimiento, las redes semánticas y las representaciones computacionales similares a menudo se basan en el concepto del triplete Sujeto-Verbo-Objeto, incluso si se hace referencia a los componentes individuales usando términos diferentes (es decir, relaciones en tripletes RDF o predicados en lógica bases de conocimiento).

El auge de la web semántica ha fomentado la creación de ontologías y bases de conocimiento a gran escala en varios dominios.
Algunas ontologías representan dominios generales, como DBPedia, y recopilan una gran proporción del conocimiento humano común.
Otros, como Ivanovic y Budimac~\cite{IVANOVIC20145158} operan en un dominio más específico pero incorporan datos más detallados sobre el dominio.
Uno de los mayores obstáculos para el desarrollo de la web semántica es la cantidad de esfuerzo y tiempo que necesitan los expertos humanos para construir ontologías a mano~\cite{gomez2006ontological, petasis2011ontology}.
En este sentido, el campo del aprendizaje de la ontología~\cite{buitelaar2005ontology} estudia las técnicas y metodologías que permiten la extracción automática o semiautomática de ontologías de fuentes de información no estructuradas, como el texto natura~\cite{mitchell2015never,Balahur2011}.

Una de las cuestiones más importantes en el aprendizaje de ontología a partir del texto natural es cómo reconocer qué conocimiento es relevante en un dominio. Por lo general, en un corpus de texto natural, una gran parte de la información será falsa o sin importanci~\cite{Kanya2009InformationE}.
Los seres humanos tienen una capacidad innata para olvidar los hechos espurios o sin importancia que se nos presentan a diario, y solo almacenan a largo plazo ese conocimiento que es relevante para un propósito particular.
Se han propuesto varias métricas relevantes~\cite{manning2008introduction, brank2005survey}.
En general, el conocimiento más relevante puede estar relacionado con las acciones y conceptos que aparecen con mayor frecuencia en un dominio.

% PAPER JBI

El crecimiento exponencial de Internet en las últimas décadas ha producido un excedente masivo de información textual en todas las áreas del quehacer humano. Este escenario presenta tanto una oportunidad como un desafío para los investigadores. Por un lado, se dispone de una cantidad cada vez mayor de literatura científica, donde se podrían encontrar posibles soluciones para problemas críticos vinculando resultados parciales publicados en distintos documentos. Por otro lado, la extensión de la información disponible no puede ser procesada por humanos solos en un período de tiempo razonable. Por lo tanto, los esfuerzos se han dirigido recientemente hacia el diseño de técnicas automáticas que pueden descubrir piezas de información relevantes en grandes corpora, establecer conexiones lógicas y sintetizar conocimientos útiles.
El primer paso en muchas de estas técnicas implica la recopilación, el procesamiento y la anotación de datos que se pueden usar para entrenar algoritmos de aprendizaje automático o construir sistemas expertos mediante el uso de técnicas de procesamiento del lenguaje natural.

El sector de la salud digital es de gran interés para la comunidad investigadora dados los posibles beneficios sociales derivados de la aplicación de tecnologías de descubrimiento automático del conocimiento. La comunidad de investigación ha producido una gran cantidad de corpus anotados en diferentes subdominios de este sector, desde interacciones específicas (p. Ej., Fármaco-enfermedad~\cite{goldberg1996drug} o interacciones gen-proteína~\cite{tanabe2005genetag}) hasta amplio alcance y dominio (por ejemplo, informes de ensayos clínico ~\cite{nye2018corpus}).
Los corpus y las tecnologías de dominios específicos son de vital importancia en la medicina de alta precisión.
Sin embargo, los sistemas construidos para dominios muy específicos son posiblemente más difíciles de generalizar y extender que los sistemas construidos sobre conceptualizaciones de propósito general.
Como tal, existe un interés creciente en diseñar modelos de anotación y corpus con semántica de propósito general que se puedan usar en una variedad de dominios o como un componente en sistemas más especializados.

Además del dominio, el lenguaje es otra dimensión que ha sido el foco de investigaciones recientes.
La mayoría de los recursos lingüísticos más importantes se basan en fuentes del inglés, motivados en parte por la abundancia de materia prima disponible~(por ejemplo, enciclopedias en línea, trabajos de investigación), lo cual no es sorprendente dado que el inglés es el idioma más predominante en ciencia, tecnología y comunicaciones.
Sin embargo, los recursos en inglés no siempre son directamente aplicables a otros idiomas.
Aunque la traducción automática ha alcanzado una precisión impresionante en dominios abiertos, sigue siendo un desafío crear recursos en varios idiomas, como el español, que es menos predominante en los dominios técnicos~\cite{villegas2018mespen}.
En lugar de centrarse en lenguajes de nicho específicos, una posible línea de investigación es diseñar recursos que sean agnósticos del lenguaje, en el sentido de que se puedan generalizar a varios lenguajes con poco esfuerzo, en virtud de que se basan en características comunes subyacentes compartidas por muchos lenguajes. .

El diseño de modelos de anotaciones que puedan generalizarse a varios dominios requiere decidir una representación básica del lenguaje que cubra una amplia gama de semánticas.
Además, estas representaciones deben ser lo más independientes posible de la sintaxis y las reglas gramaticales, si se espera que se generalicen a varios idiomas.
Un trabajo reciente~\cite{estevez2018gathering} sugiere que los tripletes Sujeto-Acción-Objetivo pueden usarse para detectar una gran cantidad de interacciones semánticas en lenguaje natural, independientemente del dominio y relativamente independientes del lenguaje, ya que
más del 75 \% de los lenguajes humanos emplean alguna variación de la estructura gramatical Sujeto-Verbo-Objeto~\cite{crystal2004cambridge}.
Asimismo, varias representaciones ontológicas a menudo concuerdan en una serie de relaciones de propósito general, (por ejemplo, \textit{es-a} hipónimos, \textit{parte-de} holónimos) que son útiles en cualquier dominio.
Otras conceptualizaciones permiten capturar la semántica más cercana al lenguaje natural, como la Representación de significado abstracto, AMR~\cite{banarescu2013abstract}.
La construcción de corpus anotados con estructuras semánticas de propósito general como sujeto-acción-objetivo y relaciones ontológicas de alto nivel es el primer paso en el diseño de sistemas que pueden descubrir conocimiento automáticamente en una variedad de dominios y escenarios.

La investigación en el descubrimiento del conocimiento requiere no solo recursos lingüísticos~(por ejemplo, corpus anotados) sino también recursos e infraestructuras computacionales que permitan a los investigadores evaluar sistemáticamente sus resultados y compararlos objetivamente con enfoques alternativos.
Esto implica la definición formal de tareas y el diseño de métricas de evaluación objetivas que aseguren que es posible una comparación justa.
Aún mejor es un sistema de evaluación disponible públicamente donde los investigadores pueden presentar sus resultados, garantizando que se apliquen los mismos criterios de evaluación y liberando a los investigadores de reproducir el entorno de evaluación. Dicho sistema también garantizaría un proceso de investigación más transparente y reproducible, y proporcionaría un depósito centralizado de los enfoques existentes, lo que ayudaría a los nuevos investigadores a actualizarse sobre el estado de la técnica.

% RESUMEN DEL PROCESO

- explicar el proceso y las tareas
- definir un esquema de anotacion, modelo semántico, que sea bueno
- herramientas con las que hacer la anotacion
- anotación asistida y utilidades para anotar mejor
- anotar un corpus con metricas de calidad y merging, hablar de la metodologia de anotacion
- entrenar sistemas de machine learning para la extraccion automática
- diseñar entornos de evaluación (challenges) para comparar sistemas
- construir ontologías

\section{Modelos Semánticos de Anotación}

El descubrimiento del conocimiento es un campo de la informática que muestra un crecimiento acelerado en las últimas tres décadas.
Los avances en esta área se han aplicado en muchos dominios, desde bases de datos~\cite{fayyad1996data, knowledgeDatabase} hasta imágenes~\cite{lu2016visual} y texto en lenguaje natural~\cite{carlson2010toward}.
Específicamente en el texto en lenguaje natural, este campo es de gran relevancia en los dominios biomédico y de salud, donde se utiliza para realizar tareas como
Reconocimiento de entidades nombradas~(NER), extracción de relaciones y generación de hipótesis, entre otros.~\cite{simpson2012biomedical}.
Estas tareas generalmente utilizan corpus anotados para aprender las características que aparecen en el texto y mapearlas con las estructuras de conocimiento.
Para cada tarea, se han diseñado modelos de anotaciones específicos que se enfocan en elementos específicos del texto.
Por ejemplo, en las tareas NER es más importante centrarse en frases nominales que en otras construcciones gramaticales.

A pesar de que estas tareas específicas de dominio son diferentes, la mayoría de ellas comparten características comunes. Por ejemplo, la mayoría de las tareas se ocupan de la detección de entidades relevantes y sus relaciones. Por lo tanto, la promoción de modelos de anotación de propósito general permitiría el diseño de técnicas de descubrimiento de conocimiento reutilizables y entre dominios.
En esta línea, se han desarrollado varias representaciones semánticas independientes del dominio~(por ejemplo, AMR~\cite{amr}, PropBank~\cite{propbank}, FrameNet~\cite{framenet}).
Sin embargo, estas representaciones se basan en gran medida en léxicos detallados que definen roles semánticos específicos para el significado de cada palabra. Por tanto, desarrollar sistemas de descubrimiento de conocimiento con este nivel de detalle supone grandes retos. El uso de una representación semántica más burda, incluso con la pérdida de cierta capacidad de representación, simplificaría la creación de técnicas automáticas basadas en el aprendizaje automático.
Esta representación también podría usarse como la primera etapa en una canalización para una tarea específica de dominio, reutilizando así recursos y técnicas en dominios con pocos recursos disponibles.
En esta sección presentamos una revisión de los modelos de anotaciones relevantes en los que nos inspiramos.
Nos centramos en los modelos de anotación de propósito general así como en los modelos de anotación que se han aplicado al dominio de salud.

Para proporcionar resultados de búsqueda más detallados, los documentos se pueden procesar para extraer las entidades semánticas relevantes y los hechos mencionados.
La tarea de descubrir automáticamente el conocimiento semántico a partir del texto está cubierta por áreas de investigación como el aprendizaje de ontología~\cite{cimiano2009ontology} y {aprender leyendo}~\cite{barker2007learning},
cuyo propósito es construir redes semánticas que {capturen} el conocimiento presente en grandes colecciones de texto.
Estas redes semánticas permiten el uso de motores de búsqueda que brindan un análisis más allá de la relevancia del contenido textual, explotando la estructura semántica de la red.
En este contexto, el procesamiento de contenidos textuales de salud ha despertado un {gran interés}~\cite{gonzalez2017capturing}, motivado por la gran cantidad de documentos médicos publicados anualmente.

Existen varios enfoques para construir representaciones semánticas del conocimiento.
En muchos casos, estas representaciones utilizan una conceptualización específica de dominio.
Aunque esto proporciona una representación más especializada, hace que estos enfoques sean más difíciles de aplicar a una amplia gama de dominios.
Alternativamente, se podría utilizar una conceptualización de propósito general, que sea capaz de representar entidades y hechos de múltiples dominios de conocimiento.
Tal conceptualización debería ser lo suficientemente general como para dar cabida a muchos dominios diferentes, pero aún para proporcionar un grado de expresividad necesario para las tareas de extracción de conocimiento.
Una posible conceptualización es utilizar
  {Trillizos de sujeto-acción-objetivo}~\cite{suilan2018}.
Esta estructura ha demostrado ser útil para representar el conocimiento en dominios específicos, como críticas de películas~\cite{suilan2018} o sentimiento.
Además, los tripletes Sujeto-Acción-Destino extraídos automáticamente del texto se pueden vincular posteriormente a relaciones específicas de dominio mediante el uso de redes semánticas.
Como ejemplo, el sistema \textit{SemRep}~\cite{semrep} extrae tripletes Sujeto-Predicado-Objeto de textos naturales de eSalud. Los predicados están vinculados a relaciones específicas en la red semántica UMLS~\cite{umls}.

Un trabajo reciente en el desarrollo de teleologías~\cite{teleologies} sugiere que los tripletes Acción-Sujeto-Objetivo pueden ser la base para conceptualizaciones de propósito general en muchos dominios diferentes, ya que este triplete permite la captura de interacciones entre objetos a través de las acciones que realizan en El uno al otro.
Un pequeño conjunto de relaciones semánticas, como \textit{hiponomía} y \textit{holonomía} pueden proporcionar una estructura semántica adicional a la RAM.
representación. Estas relaciones ``generales'' son comunes en la mayoría de las bases de conocimiento, independientemente del dominio, como WordNet~\cite{miller1998wordnet},
DBPedia~\cite{lehmann2015dbpedia} y ConceptNet~\cite{conceptnet}.
Otras posibles conceptualizaciones permiten capturar la semántica del lenguaje natural, como la Representación de significado abstracto~(AMR)~\cite{amr}. A pesar del poder de representación superior de AMR sobre estructuras simples como los tripletes Acción-Sujeto-Objetivo {y semántica básica
relaciones}, el proceso de anotación para la resistencia a los antimicrobianos es considerablemente más complejo tanto para humanos como para técnicas automatizadas.

La construcción de corpus anotados con la estructura Acción-Sujeto-Objetivo es el primer paso hacia el diseño de sistemas que puedan extraer automáticamente estas anotaciones. Existen varios corpus en la literatura, anotados con una variedad de esquemas diferentes, como CLEF~\cite{kelly2016overview}, Yago~\cite{suchanek2007yago} y Emotinet~\cite{Balahur2011}.
Sin embargo, la mayoría de estos recursos están anotados con conceptualizaciones específicas de dominio que son difíciles de extender a diferentes dominios de conocimiento.

\subsection{General-purpose annotation models}\label{sec:general}

Se han desarrollado varios modelos de anotación semántica de propósito general, que intentan representar la semántica de una oración más allá de la estructura sintáctica.
Estos modelos se basan libremente en la estructura gramatical Sujeto-Verbo-Objeto que es omnipresente en el lenguaje humano.

\paragraph{PropBank}

PropBank~\cite{propbank} propone un esquema de anotación de propósito general, basado en predicados de anotación (verbos) como los principales constituyentes semánticos de una oración. El esquema de anotación de ProbBank es capaz de representar varias relaciones semánticas, incluido el agente que causa una acción, el receptor de los efectos de una acción, modificadores de tiempo y ubicación y relaciones causales.
Una característica clave de PropBank es que cada predicado define roles semánticos personalizados, es decir, el predicado `` \textit{accept} '' define roles para el agente que acepta~(\texttt{ARG0}), el objeto que se acepta~(\texttt{ARG1}) y el agente de quien se acepta ese objeto.

Nuestro esquema de anotaciones se desarrolló a partir de un consenso entre los grupos de investigación de BBN, MITRE, la Universidad de Nueva York y Penn. Se acordó que la primera fase de la anotación se centraría en los predicados verbales, dejando a un lado los adjetivos, los sustantivos deverbales y los predicados nominativos para una etapa posterior.
Se eligieron etiquetas de argumentos que pudieran mapearse fácilmente en las etiquetas utilizadas en la mayoría de las teorías modernas de estructura de argumentos sin estar especialmente en deuda con ninguna teoría en particular.
Por tanto, los argumentos se numeran como Arg0, Arg1, Arg2, etc., según la valencia del verbo en cuestión. El significado de cada etiqueta de argumento se define en relación con cada verbo en un léxico de 'Archivos de marcos'. Cada conjunto de etiquetas de argumento y sus definiciones se denomina conjunto de marcos y proporciona un identificador único para el sentido del verbo, un significado para ese sentido del verbo y el conjunto de argumentos esperados que dan tanto los números Arg como una etiqueta o descripción mnemotécnica para ese Arg.
A continuación de las definiciones hay una serie de oraciones de ejemplo que demuestran varias realizaciones sintácticas para ese conjunto de marcos.

El material de capacitación para el reconocimiento de propuestas, PropBank, está siendo anotado en inglés, basado en un consenso desarrollado en 2000 entre grupos de investigación de BBN, MITRE, New York University y Penn. Tomando como punto de partida el Corpus del Penn Treebank II Wall Street Journal de un millón de palabras (Marcus 1994), estamos agregando una anotación de estructura de argumento predicado. Aproximadamente una cuarta parte del TreeBank, que comprende en gran parte textos de informes financieros, ha sido extraído y sirve como nuestro enfoque inicial para la capacitación y para proporcionar una entrega más temprana de texto con anotaciones completas. Este subcorpus debe completarse en junio de 2002, mientras que el resto del corpus se completará en el verano de 2003. El proyecto actual solo anota predicados verbales, dejando de lado nominalizaciones, adjetivos y preposiciones para una fase posterior. En un artículo separado (Kingsbury, Marcus \& Palmer, de próxima publicación) discutimos las diferencias entre PropBank y recursos similares como Verbnet, Wordnet y Framenet. Al crear anotaciones para la estructura del argumento, se usa una combinación de factores sintácticos y semánticos, aunque las claves sintácticas son las más importantes. El método general es el siguiente: para cualquier predicado dado, se hace un estudio de los usos del predicado y los usos se dividen en sentidos principales si es necesario. Estos sentidos están divididos más por motivos sintácticos que semánticos, evitando así las divisiones detalladas y a menudo arbitrarias de, por ejemplo, WordNet. Los argumentos esperados de cada sentido se numeran secuencialmente desde Arg0 a Arg5. De acuerdo con las pautas establecidas por la comunidad ACE descritas anteriormente, no se intenta hacer que las etiquetas de los argumentos tengan el mismo "significado" de un sentido de un verbo a otro, por ejemplo, el "papel" que juega Arg2 en un sentido de un Arg3 puede jugar un predicado dado en otro sentido. Por otro lado, pretendemos que los predicados que pertenecen a la misma clase VerbNet compartan 2 BBN etiquetados de manera similar ya ha completado la anotación de co-referencia de pronombre en los mismos argumentos de datos, de acuerdo con la casi sinonimia de los predicados.

\paragraph{FrameNet}

FrameNet~\cite{framenet} es una base de datos léxica y un corpus anotado que modela los roles semánticos y las relaciones en una oración en lenguaje natural a través de estructuras conceptuales llamadas \textit{frames}. Los marcos representan conceptos de propósito general, o eventos, que definen las posibles relaciones semánticas en las que esos conceptos pueden realizarse en lenguaje natural.

FrameNet se basa en una teoría del significado llamada Frame Semantics, derivada del trabajo de Charles J. Fillmore y sus colegas (Fillmore 1976, 1977, 1982, 1985, Fillmore y Baker 2001, 2010). La idea básica es sencilla: que los significados de la mayoría de las palabras pueden entenderse mejor sobre la base de un marco semántico, una descripción de un tipo de evento, relación o entidad y los participantes en él. Por ejemplo, el concepto de cocinar generalmente involucra a una persona que cocina (Cocinar), la comida que se va a cocinar (Comida), algo para sostener la comida mientras se cocina (Recipiente) y una fuente de calor (Instrumento de calentamiento). En el proyecto FrameNet, esto se representa como un marco llamado Apply\_heat, y Cook, Food, Heating\_instrument y Container se denominan elementos de marco (FE). Las palabras que evocan este marco, como freír, hornear, hervir y asar, se denominan unidades léxicas (LU) del marco Apply\_heat. Otros marcos son más complejos, como Revenge, que involucra más FE (Delincuente, Lesión, Lesionado\_Party, Avenger y Castigo) y otros son más simples, como Colocar, con solo un Agente (o Causa), una cosa que es colocado (llamado Tema) y la ubicación en la que se coloca (Objetivo).

La entrada léxica para cada LU se deriva de tales anotaciones y especifica las formas en que los FE se realizan en estructuras sintácticas encabezadas por la palabra.

Muchos sustantivos comunes, como árbol, sombrero o torre, suelen servir como dependientes que encabezan FE, en lugar de evocar claramente sus propios marcos, por lo que hemos dedicado menos esfuerzo a anotarlos, ya que la información sobre ellos está disponible en otros léxicos, como WordNet (Miller et al. 1990). Sin embargo, reconocemos que dichos sustantivos también tienen una estructura de marco mínima propia y, de hecho, la base de datos FrameNet contiene un poco más de sustantivos que de verbos.

Formalmente, las anotaciones de FrameNet son conjuntos de triples que representan las realizaciones de EF para cada oración anotada, cada una de las cuales consta de un nombre de elemento de marco (por ejemplo, Comida), una función gramatical (por ejemplo, Objeto) y un tipo de frase (por ejemplo, frase nominal ( NOTARIO PÚBLICO)). Podemos pensar en estos tres tipos de anotaciones en cada FE como "capas", pero la función gramatical y las capas de tipo de frase no se muestran en el sistema de informes basado en la web, para evitar el desorden visual. La versión XML descargable de los datos incluye estas tres capas (y varias más que no se comentan aquí) para todas las oraciones anotadas, junto con descripciones completas de marco y FE, relaciones marco-marco y entradas léxicas para cada LU anotado. La mayoría de las anotaciones son de oraciones separadas anotadas para una sola LU, pero también hay una colección de textos en los que se han anotado todas las palabras que evocan marcos; los marcos superpuestos proporcionan una rica representación de gran parte del significado de todo el texto. El equipo de FrameNet ha definido más de 1.000 marcos semánticos y los ha vinculado mediante un sistema de relaciones de marcos, que relacionan marcos más generales con marcos más específicos y proporcionan una base para razonar sobre eventos y acciones intencionales.

Debido a que los marcos son básicamente semánticos, a menudo son similares en todos los idiomas; por ejemplo, los marcos sobre compra y venta involucran al comprador, vendedor, bienes y dinero de FE, independientemente del idioma en el que se expresen. Se están llevando a cabo varios proyectos para construir FrameNets paralelos al proyecto FrameNet en inglés para idiomas de todo el mundo, incluidos el español, alemán, chino y japonés, y se han llevado a cabo análisis y anotaciones semánticas de marcos en áreas especializadas, desde la terminología legal hasta el fútbol y el turismo.

\paragraph{VerbNet}

VerbNet~\cite{verbnet} es un léxico verbal que también define roles semánticos específicos para cada verbo. En VerbNet, los verbos se organizan en una jerarquía y se vinculan a través de diferentes roles temáticos, como agentes, causa, fuente o tema. Estos elementos permiten captar la representación semántica de oraciones.
Los roles semánticos de PropBank son similares a los roles temáticos definidos en VerbNet y los elementos de marco en FrameNet. Como tal, existen recursos que vinculan estas estructuras semánticas~\cite{semlink}.

VerbNet (VN) (Kipper-Schuler 2006) es la red en línea más grande de verbos en inglés que vincula sus patrones sintácticos y semánticos. Es un léxico jerárquico, independiente del dominio y de amplia cobertura del verbo con asignaciones a otros recursos léxicos, como WordNet (Miller, 1990; Fellbaum, 1998), PropBank (Kingsbury y Palmer, 2002) y FrameNet (Baker et al. , 1998). VerbNet está organizado en clases de verbos que amplían las clases de Levin (1993) mediante el refinamiento y la adición de subclases para lograr coherencia sintáctica y semántica entre los miembros de una clase. Cada clase de verbo en VN está completamente descrita por roles temáticos, preferencias de selección de los argumentos y marcos que consisten en una descripción sintáctica y una representación semántica con estructura de subeventos modelada en el Modelo de Evento Dinámico de Pustejovsky y Moszkowicz (2011) y Pustejovsky (2013) .

Cada clase VN contiene un conjunto de descripciones sintácticas, o marcos sintácticos, que describen las posibles realizaciones superficiales de la estructura del argumento para construcciones como transitivo, intransitivo, frases preposicionales, resultantes y un gran conjunto de alternancias de diátesis. Las restricciones semánticas (como animada, humana, organización) se utilizan para restringir los tipos de roles temáticos permitidos por los argumentos, y se pueden imponer restricciones adicionales para indicar la naturaleza sintáctica del constituyente que probablemente esté asociado con el rol temático. Los marcos sintácticos también pueden estar restringidos en términos de qué preposiciones están permitidas. Cada cuadro está asociado con información semántica explícita, expresada como una conjunción de predicados semánticos booleanos como "movimiento", "contacto" o "causa". Cada predicado semántico está asociado con una variable de evento E que permite a los predicados especificar cuándo en el evento el predicado es verdadero (inicio (E) para la etapa preparatoria, durante (E) para la etapa de culminación y final (E) para la etapa consecuente ). La Figura 1. muestra una entrada completa para un marco en la clase VerbNet Hit-18.1.

VerbNet se ha integrado recientemente con 57 nuevas clases de la extensión propuesta de Korhonen y Briscoe (2004) (K \& B) a la clasificación original de Levin (Kipper et al., 2006). Este trabajo ha implicado asociar descripciones sintáctico-semánticas detalladas a las clases K \& B, así como organizarlas apropiadamente en la taxonomía VN existente. También se ha incorporado a VN un conjunto adicional de 53 clases nuevas de Korhonen y Ryant (2005) (K \& R). El resultado es un recurso de libre acceso que constituye la clasificación de verbos al estilo Levin más completa y versátil para inglés. Después de las dos extensiones, VN ahora también ha aumentado nuestra cobertura de tokens de PropBank (Palmer et. Al., 2005) del 78,45 \% al 90,86 \%, lo que hace factible la creación de un corpus de capacitación sustancial anotado con etiquetas de roles temáticos de VN y membresía de clase. asignaciones, que se publicará en 2007. Esto permitirá finalmente la experimentación a gran escala sobre la utilidad de las clases basadas en sintaxis para mejorar el rendimiento de analizadores sintácticos y etiquetadoras de roles semánticos en nuevos dominios.

A cada argumento verbal se le asigna un rol temático (generalmente único) dentro de la clase. Algunas excepciones a esta unicidad son las clases que contienen verbos con argumentos simétricos, como la clase Chitchat-37.6 o la clase ContiguousLocation-47.8. Estas clases tienen roles indexados como Actor1 y Actor2, como se explicó anteriormente.

\paragraph{AMR}

Una propuesta más reciente es Representación de significado abstracto~\cite[ARM]{amr}. AMR constituye un esquema de representación semántica para oraciones en inglés que también intenta cubrir una amplia gama de relaciones semánticas con un modelo de propósito general.
AMR incluye roles semánticos de PropBank, así como resolución de correferencia dentro de la misma oración, entidades y tipos nombrados, negación y otros modificadores en una estructura gráfica que representa el significado de una oración en lenguaje natural.
Sin embargo, a pesar de que AMR captura el significado semántico completo de una oración, para el propósito del descubrimiento del conocimiento, sigue siendo considerablemente abstracto, y es necesario un procesamiento adicional para extraer estructuras concretas de conocimiento~\cite{rao2017biomedical}.

Nuestros principios básicos son:
Los AMR son gráficos enraizados y etiquetados que son fáciles de leer para las personas y fáciles de recorrer para los programas.
AMR tiene como objetivo abstraerse de las idiosincrasias sintácticas. Intentamos asignar el
mismo AMR a oraciones que tienen el mismo significado básico. Por ejemplo, a las frases “la describió como un genio”, “su descripción de ella: genio” y “ella era un genio, según su descripción” se les asigna el mismo AMR.
AMR hace un uso extensivo de los conjuntos de marcos PropBank (Kingsbury y Palmer, 2002; Palmer et al., 2005). Por ejemplo, representamos una frase como "inversor en bonos" utilizando el marco "invertir-01", aunque no aparecen verbos en la frase.
AMR es agnóstico sobre cómo podríamos querer derivar significados de cadenas, o viceversa. Al traducir oraciones a AMR, no dictamos una secuencia particular de aplicaciones de reglas ni proporcionamos alineaciones que reflejen dichas secuencias de reglas. Esto hace que el sembanking sea muy rápido y permite a los investigadores explorar sus propias ideas sobre cómo se relacionan las cadenas con los significados.
AMR está fuertemente sesgado hacia el inglés. No es un interlingua.

El modelo de anotación propuesto en esta investigación comparte similitudes con los modelos de anotación semántica de propósito general como AMR y PropBank.
En contraste con estos recursos, nuestro modelo no distingue entre diferentes tipos de acciones, que están vagamente relacionadas con los verbos. En cambio, definimos dos roles de propósito general, el agente que realiza una acción y el receptor de los efectos de la acción. Estos roles corresponden aproximadamente a \texttt{ARG0} y \texttt{ARG1} respectivamente en PropBank, aunque en casos específicos su significado semántico puede diferir.
Esta simplificación está dirigida a permitir la automatización del proceso de anotación con el uso de técnicas de aprendizaje automático.
Otra diferencia clave de nuestro modelo es la inclusión de relaciones taxonómicas de propósito general~(por ejemplo, \textit{hipernomía} / \textit{hiponomía} y \textit{merónimo} / \textit{holónimo}) que se infieren de la oración. Estas relaciones están dirigidas a facilitar la construcción automática de bases de conocimiento.

\subsection{Annotations models in the health domain}\label{sec:health}

Las tareas de descubrimiento de conocimientos en el ámbito de la salud suelen estar respaldadas por la construcción de corpus anotados manualmente.
Se han desarrollado varios modelos de anotaciones para tareas específicas con este fin. Un ejemplo es el {DrugSemantics} corpus~\cite{moreno2017drugsemantics} donde se anotan las características del producto, y {BARR2}~\cite{barr2} que se ocupa de las abreviaturas biomédicas.
Muchos corpus incluyen tipos específicos de entidades nombradas relevantes para el dominio médico, como {DDI}~\cite{ddi} que anota medicamentos y otras sustancias.
Otros ejemplos incluyen {i2b2}~\cite{i2b2} que anota medicamentos, dosis y otros detalles de la administración de medicamentos y {CLEF}~\cite{clef} que anota diferentes tipos de condiciones, dispositivos y sus resultados en casos clínicos específicos.
Dada la especificidad de los conceptos anotados, la mayoría de estos recursos son construidos por expertos en biomedicina.

Los ejemplos anteriores son corpus útiles para diseñar técnicas orientadas a tareas limitadas,
donde el modelo de anotación está diseñado específicamente para considerar solo partes del texto relevantes para los conceptos de intereses (es decir, entidades médicas, genes, etc.).
Un enfoque alternativo que intenta modelar una amplia gama de semánticas de un documento es {Bio-AMR}~\cite{bioamr}.
Este corpus contiene oraciones relacionadas con la salud anotadas con su estructura AMR, una representación semántica de propósito general del texto natural.
Otro recurso relevante es BioFrameNet~\cite{bioframenet}, una extensión de FrameNet con roles semánticos específicos para el dominio biomédico.
Una consecuencia positiva del uso de anotaciones semánticas de propósito general es que no necesariamente requiere expertos en áreas biomédicas para participar en el proceso de anotación.

El {eHealth-KD} corpus~\cite{martinez2018overview} intenta alcanzar un término medio al representar una amplia gama de conocimientos con un modelo de anotación simple basado en tripletes Sujeto-Acción-Objetivo y 4 relaciones semánticas adicionales.
Sin embargo, después del proceso de anotación se identificaron varias deficiencias.
Un ejemplo es la necesidad de incluir {causalidad} y {vinculación} como relaciones explícitas, en lugar de representarlas a través de acciones, dada la importancia de este tipo de afirmaciones en los textos médicos.
Asimismo, la anotación carece de la capacidad de representar correferencias (`` \textit{esto} '', `` \textit{eso} '') y, por esta razón, muchas oraciones no se pueden anotar completamente.
Además, las construcciones lingüísticas complejas que representan conceptos compuestos (por ejemplo, `` \textit{los pacientes que recibieron tratamiento} '') son difíciles de anotar, especialmente cuando participan en otras relaciones.
Este artículo amplía el modelo de anotación utilizado por el corpus eHealth-KD con elementos semánticos utilizados en modelos de anotación de propósito general, como AMR y PropBank.
Esta extensión permite resolver los problemas antes mencionados y aumenta su poder de representación sin agregar un conjunto demasiado complejo de nuevos roles y relaciones semánticas.

\section{Herramientas de Anotación}

Un elemento importante a considerar en la investigación del Descubrimiento del Conocimiento es la existencia de recursos e infraestructura computacionales que apoyan el desarrollo de nuevos enfoques.
La creación de recursos lingüísticos a menudo surge de un proceso de anotación manual por parte de expertos humanos, que requiere herramientas computacionales para la anotación real, así como mecanismos para fusionar anotaciones y acuerdo de computación, idealmente en un entorno colaborativo.
Una vez que se crean los recursos, es necesario distribuir el corpus, las líneas de base y las herramientas correspondientes entre la comunidad de investigación, a menudo a través de plataformas de intercambio de código fuente en línea.

En~\citet{annotation-tools} se proporciona un análisis extenso y una comparación de varias herramientas de anotación.
La tabla~\ref{tab:annotation-tools} resume las principales características que consideramos relevantes para esta investigación e identifica la herramienta de anotación más apropiada entre un subconjunto de alternativas populares.
Consideramos como requisitos herramientas de anotación de código abierto basadas en la web que permiten anotaciones de tramo de etiquetas múltiples, así como anotaciones de relación. El soporte para la anotación colaborativa, al menos parcialmente, también es muy deseable.
De las herramientas analizadas, identificamos Brat~\cite{brat} y WebAnno~\cite{webanno}, ya que cumplen con todos los requisitos antes mencionados. En nuestra investigación, preferimos Brat a WebAnno porque, aunque WebAnno ofrece más funciones, Brat permite una configuración más sencilla. No solo es más rápido iniciar un proyecto de anotación con esta herramienta, sino también capacitar a los anotadores para que utilicen su interfaz.

\begin{table}[htb]
  \centering
  \resizebox{\textwidth}{!}{
    \begin{tabular}{r|cccccccccccc}
      \textbf{Characteristics} & \rotatebox{90}{\textbf{GATE Teamware}} & \rotatebox{90}{\textbf{Knowtator}} & \rotatebox{90}{\textbf{WebAnno}} & \rotatebox{90}{\textbf{Brat}} & \rotatebox{90}{\textbf{BioQRator}} & \rotatebox{90}{\textbf{CATMA}} & \rotatebox{90}{\textbf{prodigy}} & \rotatebox{90}{\textbf{TextAE}} & \rotatebox{90}{\textbf{LightTag}} & \rotatebox{90}{\textbf{Djangology}} & \rotatebox{90}{\textbf{MyMiner}} & \rotatebox{90}{\textbf{WAT-SL}} \\ \midrule
      multi-label annotations  &                                        &                                    & \ok                              & \ok                           &                                    & \ok                            &                                  &                                 & \ok                               & \ok                                 &                                  &                                 \\ % F1
      relation annotations     &                                        & \ok                                & \ok                              & \ok                           & \ok                                &                                &                                  & \ok                             & \ok                               &                                     & \ap                              &                                 \\ % F3
      allows custom model      & \ok                                    & \ok                                & \ok                              & \ok                           & \ok                                & \ok                            & \ok                              & \ok                             & \ok                               & \ok                                 & \ok                              & \ok                             \\ %
      collaborative interface  & \ok                                    &                                    & \ap                              & \ap                           & \ap                                & \ap                            & \ap                              &                                 & \ok                               & \ok                                 &                                  & \ap                             \\ % F10
      web-based interface      & \ok                                    &                                    & \ok                              & \ok                           & \ok                                & \ok                            & \ok                              & \ok                             & \ok                               & \ok                                 & \ok                              & \ok                             \\ %
      can be self-hosted       & \ok                                    & \ok                                & \ok                              & \ok                           &                                    & \ok                            & \ok                              & \ok                             &                                   & \ok                                 &                                  & \ok                             \\ %
      open source license      & \ok                                    & \ok                                & \ok                              & \ok                           &                                    & \ok                            &                                  & \ok                             &                                   & \ok                                 & \ok                              & \ok                             \\ % T2
      citation                 & \cite{gate}                            & \cite{knowtator}                   & \cite{webanno}                   & \cite{brat}                   & \cite{bioqrator}                   & \cite{catma}                   & \cite{prodigy}                   & \cite{textae}                   & \cite{lighttag}                   & \cite{djangology}                   & \cite{myminer}                   & \cite{watsl}                    \\
      \bottomrule
    \end{tabular}}
  \caption{Qualitative comparison of popular annotation tools. Adapted from Table 3 in~\citet{annotation-tools}, Table~3. A symbol~\ap~indicates that the corresponding feature is only partially supported.}
  \label{tab:annotation-tools}
\end{table}

\subsection{Descripción de las herramientas de anotación}

\begin{description}
  \item[GATE Teamware] es una herramienta de anotación de texto de código abierto y una metodología para la implementación y el apoyo de proyectos de anotación complejos. Tiene una arquitectura basada en web, donde una serie de servicios web (por ejemplo, almacenamiento de documentos, anotación automática) están disponibles a través de HTTPS y los usuarios interactúan con las interfaces de anotación de texto a través de un navegador web estándar.

        GATE Teamware se basa en GATE (Cunningham et al. 2011b), una plataforma de PNL de código abierto ampliable, robusta y ampliamente utilizada. GATE viene con numerosos componentes de procesamiento de texto reutilizables para muchos lenguajes naturales, junto con un entorno de desarrollo gráfico de PNL e interfaces de usuario para la visualización y edición de anotaciones lingüísticas, árboles de análisis, cadenas de co-referencia y ontologías. Sin embargo, GATE Teamware fue creado específicamente para ser utilizado por anotadores no expertos, así como para permitir proyectos de anotación de corpus metodológicamente sólidos, eficientes y rentables en la web.

        Además de sus usos de investigación, GATE Teamware también se ha probado como un marco para servicios de anotación comercial rentables, suministrados como unidades internas o como actividades especializadas subcontratadas. Se han llevado a cabo varios proyectos de anotación de prueba en los dominios de la bioinformática y la inteligencia empresarial, con una formación mínima y produciendo corpus de alta calidad. Por ejemplo, Meurs et al. (2011) aplican GATE Teamware a la tarea de construir una base de datos de enzimas fúngicas para la investigación de biocombustibles. Sus resultados muestran que el uso de GATE Teamware para la preanotación automática y la corrección manual aumenta la velocidad con la que se pueden procesar los documentos para su inclusión en la base de datos en un factor de alrededor del 50 \%.

        De manera similar a otro software del lado del servidor, la instalación de GATE Teamware es una tarea especializada, no trivial con costos asociados, en términos de tiempo significativo y experiencia del personal requerido. Para reducir esta barrera y proporcionar cero costos de inicio, hemos puesto a disposición máquinas virtuales GATE Teamware basadas en la nube, Footnote3, que se pueden encender y apagar según sea necesario. Además, la integración de GATECloud.net (Tablan et al. 2013) facilita la elección de un conjunto de documentos anotados automáticamente y enviarlos a una instancia de GATE Teamware. También hay una distribución de máquina virtual que se puede descargar y ejecutar localmente.

  \item[Knowtator]

        En Knowtator, un esquema de anotación se define con definiciones de clases, instancias, ranuras y facetas de Protégé utilizando la función de edición de la base de conocimientos de Protégé. El esquema de anotación definido se puede aplicar a una tarea de anotación de texto sin tener que escribir ninguna tarea.
        software específico o editar archivos de configuración especializados. Los esquemas de anotación en Knowtator pueden modelar fenómenos sintácticos (por ejemplo, análisis sintácticos superficiales) y semánticos (por ejemplo, interacciones proteína-proteína).

        Knowtator aborda la definición de un esquema de anotación como una tarea de ingeniería del conocimiento aprovechando las fortalezas de Protégé como editor de una base de conocimiento. Protégé tiene componentes de interfaz de usuario para definir marcos de clase, instancia, ranura y faceta.
        Un esquema de anotación de Knowtator se crea definiendo marcos utilizando estos componentes de interfaz de usuario como lo haría un ingeniero de conocimiento al crear un modelo conceptual de algún dominio. Para Knowtator, las definiciones de marcos modelan los fenómenos que la tarea de anotación busca capturar.

        Como ejemplo simple, la tarea de anotación de co-referencia que viene con Callisto se puede modelar en Protégé con dos definiciones de clase llamadas marcables y encadenadas. La clase de cadena tiene dos referencias de ranuras y primary\_reference que están restringidas por facetas para tener valores de tipo marcables. Este esquema de anotación simple ahora se puede usar para anotar fenómenos de co-referencia que ocurren en el texto usando Knowtator. Anotaciones en Knowtator creadas con este sencillo esquema de anotaciones.

        Una fortaleza clave de Knowtator es su capacidad para relacionar anotaciones entre sí a través de las definiciones de ranuras de las clases anotadas correspondientes. En el ejemplo de co-referencia, las referencias de espacio de la cadena de clases relacionan las anotaciones marcables para las extensiones de texto "el gato" y "Él" con la anotación de la cadena. Las restricciones de las ranuras garantizan que las relaciones entre las anotaciones sean coherentes.

        Protégé es capaz de representar modelos conceptuales mucho más sofisticados y complejos que pueden ser utilizados, a su vez, por Knowtator para la anotación de texto. Además, debido a que Protégé se usa a menudo para crear modelos conceptuales de dominios relacionados con disciplinas biomédicas, Knowtator es especialmente adecuado para capturar entidades con nombre y relaciones entre entidades con nombre para esos dominios.

  \item[WebAnno]

        WebAnno es la tercera versión importante de la herramienta de anotación basada en web WebAnno (Yimam et al., 2013; Yimam et al., 2014) que presenta nuevas funcionalidades que permiten la anotación de estructuras semánticas:

        1. Las características de ranura permiten el modelado apropiado de estructuras de predicado-argumento para SRL. También admitimos los siguientes tipos de anotaciones semánticas adicionales: participantes y circunstancias para la anotación de eventos, relaciones n-arias para la extracción de relaciones y tareas de relleno de espacios para la extracción de información.

        2. Las restricciones ayudan a los anotadores al realizar un filtrado sensible al contexto de los ricos conjuntos de etiquetas semánticas. Por ejemplo, el sentido de un predicado semántico determina los roles de argumento disponibles. Este filtrado es necesario para evitar perder un tiempo valioso al hacer que los anotadores busquen en una gran cantidad de etiquetas o que ingresen etiquetas manualmente. Las reglas de restricción se pueden definir manualmente o se pueden generar automáticamente, p. Ej. a partir de recursos léxicos legibles por máquina. Hasta donde sabemos, no existe ninguna otra herramienta de anotación basada en la web que ofrezca una funcionalidad comparable.

        3. Una interfaz de anotación mejorada para un proceso de anotación optimizado utilizando una barra lateral permanentemente visible en lugar de un cuadro de diálogo emergente para editar anotaciones y sus características.

        Estas nuevas funcionalidades se integran bien con las funcionalidades existentes en WebAnno 2, en particular su soporte para la anotación de estructuras sintácticas, permitiendo así la anotación semántica en coordinación con la anotación sintáctica. Hasta donde sabemos, WebAnno 3 es actualmente la única herramienta de anotación basada en la web y orientada a equipos que admite tanto la anotación de estructuras semánticas como sintácticas.

        WebAnno 3 se desarrolló e implementó en estrecha coordinación con los usuarios en el contexto de un proyecto de anotación (cf. Mujdricza-Maydt et al. (2016)) para la desambiguación del sentido de las palabras (WSD) y SRL en textos alemanes e impulsado por sus requisitos prácticos. SRL es la tarea de identificar predicados semánticos, sus argumentos y asignar roles a estos argumentos. Es una tarea difícil que suelen realizar los expertos.
        Ejemplos de esquemas de SRL bien conocidos motivados por diferentes teorías lingüísticas son FrameNet (Baker et al., 1998), PropBank (Palmer et al., 2005) y VerbNet (Kipper Schuler, 2005). La anotación de SRL se basa típicamente en estructuras sintácticas obtenidas de bancos de árboles, como el Penn Treebank basado en constituyentes (para la anotación de PropBank), o el banco de árboles TIGER alemán para la anotación de estilo FrameNet (Burchardt et al., 2009). Un argumento se identifica típicamente por la extensión de su cabeza sintáctica o constituyente sintáctico. Para algunos esquemas de anotaciones (por ejemplo, FrameNet), la tarea también incluye WSD. En este caso, la etiqueta de sentido suele determinar los espacios de argumentos disponibles. El siguiente ejemplo muestra una anotación usando FrameNet; el predicado ask recibe la etiqueta de marco Cuestionando (correspondiente a su sentido de la palabra) y sus argumentos se anotan como Destinatario, Hablante, Mensaje e Iteraciones

  \item[Brat]

        BRAT se basa en nuestro visualizador de anotaciones de texto STAV de código abierto publicado anteriormente (Stenetorp et al., 2011b), que fue diseñado para ayudar a los usuarios a comprender las anotaciones complejas que involucran una gran cantidad de tipos semánticos diferentes, anotaciones de texto densas, parcialmente superpuestas y conjuntos no proyectivos de conexiones entre anotaciones. Ambas herramientas comparten un componente de visualización basado en gráficos vectoriales, que proporcionan detalles y renderización escalables. BRAT integra la funcionalidad de exportación de formato de imagen PDF y EPS para admitir el uso en, por ejemplo, cifras en publicaciones (Figura 1).

        Ampliamos las capacidades de STAV implementando soporte para la edición de anotaciones. Esto se hizo agregando funcionalidad para reconocer gestos de interfaz de usuario estándar que son familiares de los editores de texto, software de presentación y muchas otras herramientas.
        En BRAT, un tramo de texto se marca para anotación simplemente seleccionándolo con el mouse, “arrastrando” o haciendo doble clic en una palabra. De manera similar, las anotaciones se vinculan haciendo clic con el mouse en una anotación y arrastrando una conexión a la otra.

        BRAT se basa en un navegador y se construye en su totalidad utilizando tecnologías web estándar. Por lo tanto, ofrece un entorno familiar para los anotadores y es posible comenzar a usar BRAT simplemente apuntando a una instalación con un navegador moderno que cumpla con los estándares. Por lo tanto, no es necesario instalar o distribuir ningún software de anotación adicional ni utilizar complementos del navegador. El uso de estándares web también hace posible que BRAT identifique de forma única cualquier anotación mediante los identificadores uniformes de recursos (URI), lo que permite vincular anotaciones individuales para discusiones en correo electrónico, documentos y páginas web, lo que facilita la comunicación con respecto a las anotaciones.

        BRAT es completamente configurable y se puede configurar para admitir la mayoría de las tareas de anotación de texto. La primitiva de anotación más básica identifica un intervalo de texto y le asigna un tipo (o etiqueta o etiqueta), marcando p. Ej. Tokens, fragmentos o menciones de entidad etiquetados en POS (Figura 1 arriba). Estas anotaciones base se pueden conectar mediante relaciones binarias, dirigidas o no dirigidas, que se pueden configurar para, por ejemplo, extracción de relación simple, o anotación de marco de verbo (Figura 1 en el medio y en la parte inferior). También se admiten asociaciones n-arias de anotaciones, lo que permite la anotación de estructuras de eventos como las dirigidas en el MUC (Sundheim, 1996), ACE (Doddington et al., 2004) y BioNLP (Kim et al., 2011). Tareas de extracción (IE) (Figura 2). Los aspectos adicionales de las anotaciones se pueden marcar utilizando atributos, banderas binarias o de valores múltiples que se pueden agregar a otras anotaciones.

        Finalmente, los anotadores pueden adjuntar notas de texto de forma libre a cualquier anotación. Además de las tareas de extracción de información, estas primitivas de anotación permiten configurar BRAT para su uso en varias otras tareas, como fragmentación (Abney, 1991), etiquetado de roles semánticos (Gildea y Jurafsky, 2002; Carreras y Márquez, 2005) y dependencia anotación (Nivre, 2003) (consulte la Figura 1 para ver ejemplos). Además, tanto el cliente BRAT como el servidor implementan soporte completo para el estándar Unicode, lo que permite que la herramienta admita la anotación de texto usando p. Ej. Caracteres chinos o devanagar ¯ ¯ı. BRAT se distribuye con ejemplos de más de 20 corpus para una variedad de tareas, que involucran textos en siete idiomas diferentes e incluyen ejemplos de corpus como los presentados para las tareas compartidas de CoNLL sobre el reconocimiento de entidades con nombre independientes del idioma (Tjong Kim Sang y De Meulder, 2003) y análisis de dependencia multilingüe (Buchholz y Marsi, 2006). BRAT también implementa un sistema completamente configurable para verificar restricciones detalladas en la semántica de la anotación, por ejemplo, especificando que un evento TRANSFER debe tomar exactamente uno de cada uno de los argumentos DADOR, RECIPIENTE y BENEFICIARIO, cada uno de los cuales debe tener uno de los tipos PERSON, ORGANIZATION o GEO -ENTIDAD POLÍTICA, así como un argumento DINERO de tipo DINERO, y opcionalmente puede tomar un argumento LUGAR de tipo UBICACIÓN (LDC, 2005). La verificación de restricciones está completamente integrada en la interfaz de anotaciones y la retroalimentación es inmediata, con efectos visuales claros que marcan las anotaciones incompletas o erróneas (Figura 3).

        BRAT admite dos enfoques estándar para integrar los resultados de las herramientas de anotación completamente automáticas en un flujo de trabajo de anotación: las importaciones de anotaciones masivas se pueden realizar mediante herramientas de conversión de formato distribuidas con BRAT para muchos formatos estándar (como BIO en línea y con formato de columna), y herramientas que Proporcionar interfaces de servicios web estándar que se pueden configurar para que se invoquen desde la interfaz de usuario; sin embargo, los juicios humanos no se pueden reemplazar o basar en un análisis completamente automático sin algún riesgo de introducir sesgos y reducir la calidad de las anotaciones. Para abordar este problema, hemos estado estudiando formas de aumentar el proceso de anotación con información de métodos estadísticos y de aprendizaje automático para respaldar el proceso de anotación y, al mismo tiempo, implicar el juicio del anotador humano para cada anotación. Como una realización específica basada en este enfoque, hemos integrado un sistema de desambiguación de clases semánticas basado en el aprendizaje automático introducido recientemente, capaz de ofrecer múltiples salidas con estimaciones de probabilidad que se demostró que puede reducir la ambigüedad en promedio en más del 75 \% mientras conserva el clase correcta en una media del 99 \% de los casos en seis cuerpos (Stenetorp et al., 2011a). La sección 4 presenta una evaluación de la contribución de este componente a la productividad del anotador.

        BRAT implementa un conjunto completo de funciones de búsqueda, lo que permite a los usuarios realizar búsquedas en columnas de documentos Figura 4: Las opciones del cuadro de diálogo de búsqueda de BRAT para anotaciones de texto, relaciones, estructuras de eventos o simplemente texto, con un rico conjunto de opciones de búsqueda definibles mediante un simple punto y -hacer clic
        interfaz (Figura 4). Además, los resultados de la búsqueda pueden mostrarse opcionalmente usando la concordancia de palabras clave en el contexto y ordenados para navegar
        utilizando cualquier aspecto de la anotación coincidente (por ejemplo, tipo, texto o contexto).

  \item[BioQRator]

        BioQRator (17) es una interfaz de usuario de propósito general para anotar bioentidades y relaciones. Se utilizan mensajes de red simples y mínimos para comunicarse entre BioQRator y los recursos de minería de texto. Esto le permite a uno crear fácilmente una interfaz personalizada para cualquier proyecto de bio-curación si la tarea involucrada es anotar entidades y / o relaciones. Un tema importante para los sistemas de conservación son los múltiples formatos diferentes que se utilizan. Para abordar este problema, adoptamos BioC (18, 19) como formato estándar de entrada y salida. Para la entrada, se pueden utilizar documentos con formato BioC o resúmenes de PubMed. Para la salida, los documentos anotados también se pueden guardar en formato BioC o CSV (valores separados por comas). Más importante aún, BioQRator proporciona una interfaz web interactiva fácil de usar. También es compatible con varios navegadores, incluidos Chrome, Firefox y Safari (parcialmente compatible con Internet Explorer).

        La tarea interactiva de BioCreative (IAT) es una pista diseñada para explorar las interacciones usuario-sistema, promover el desarrollo de herramientas útiles de minería de texto y proporcionar un canal de comunicación para las comunidades de biocuración y minería de texto (20, 21). Para BioCreative IV, un equipo participante definió un tema y tareas para la evaluación de los curadores. Los voluntarios biocuradores fueron asignados a los equipos participantes en función de sus intereses en temas definidos. La tarea de BioCreative IAT es especialmente significativa para las comunidades de minería de textos porque ha habido poco esfuerzo para evaluar formalmente las herramientas de curación. Para demostrar la usabilidad de BioQRator en BioCreative IV, se definió una tarea PPI y se utilizó la búsqueda PIE (22, 23) para un recurso externo de minería de texto. Se utilizaron las bases de datos necesarias como PubMed, Entrez Gene y UniProt para proporcionar enlaces web para BioQRator.

  \item[CATMA]

        CATMA (Análisis y marcado de texto asistido por computadora), una herramienta desarrollada en la Universidad de Hamburgo y utilizada actualmente por más de 60 proyectos de investigación en todo el mundo. CATMA ofrece una combinación única de tres características principales que no se encuentran en ninguna otra herramienta de análisis de texto:

        -CATMA admite la anotación y el análisis colaborativos: un texto o corpus de texto puede ser investigado individualmente, pero también de forma conjunta por un grupo de estudiantes o investigadores.

        -CATMA apoya prácticas exploratorias no deterministas de anotación de texto: un enfoque discursivo y orientado al debate para la anotación de texto basado en las prácticas de investigación de las disciplinas hermenéuticas es el modelo conceptual subyacente.

        -CATMA integra la anotación de texto y el análisis de texto en un entorno de trabajo basado en la web, lo que hace posible combinar la identificación de fenómenos textuales con su investigación de forma iterativa y sin fisuras.

        Lo que distingue a CATMA de otros métodos de anotación digital es su enfoque 'no dogmático': el sistema no prescribe esquemas o reglas de anotación definidos, ni obliga al usuario a aplicar taxonomías rígidas de sí / no, correctas / incorrectas a los textos (aunque también permite esquemas más prescriptivos). Más bien, la lógica de CATMA invita a los usuarios a explorar la riqueza y las múltiples facetas de los fenómenos textuales de acuerdo con sus necesidades: los usuarios pueden crear, expandir y modificar continuamente sus propios conjuntos de etiquetas individuales, por lo que si un pasaje de texto invita a más de una interpretación, nada en el El sistema evita la asignación de anotaciones múltiples o incluso contradictorias. A pesar de toda esta flexibilidad, CATMA no produce anotaciones idiosincrásicas: todos los datos de marcado se pueden exportar en formato TEI / XML y reutilizar en otros contextos.

        Dado que CATMA es una herramienta altamente intuitiva, también es adecuada para humanistas con poco conocimiento técnico: la GUI permite un inicio rápido y el generador de consultas de CATMA (un widget basado en diálogos paso a paso) ayuda a los usuarios a recuperar información compleja de textos sin tener que aprender un idioma de consulta. Otra ventaja en el lado fácil de usar es el hecho de que las funciones automatizadas de lectura a distancia de CATMA se mejoran y amplían continuamente: la versión actual 5.0 ya presenta una serie de rutinas de anotación automatizadas, entre otras, la identificación de características narrativas básicas en los textos.

  \item[prodigy]

        Prodigy es una herramienta de anotación moderna para crear datos de entrenamiento y evaluación para modelos de aprendizaje automático. También puede usar Prodigy para ayudarlo a inspeccionar y limpiar sus datos, realizar análisis de errores y desarrollar sistemas basados en reglas para usar en combinación con sus modelos estadísticos.

        La biblioteca de Python incluye una variedad de flujos de trabajo prediseñados y comandos de línea de comandos para varias tareas, y componentes bien documentados para implementar sus propios scripts de flujo de trabajo. Sus scripts pueden especificar cómo se cargan y guardan los datos, cambiar qué preguntas se hacen en la interfaz de anotaciones e incluso pueden definir HTML y JavaScript personalizados para cambiar el comportamiento de la interfaz. La aplicación web está optimizada para una anotación rápida, intuitiva y eficiente.

        La misión de Prodigy es ayudarlo a hacer más de todos esos procesos manuales o semiautomáticos que todos sabemos que no hacemos lo suficiente. Para la mayoría de los científicos de datos, el consejo de dedicar más tiempo a analizar sus datos es como el consejo de usar hilo dental o dormir más: es fácil reconocer que es un buen consejo, pero no siempre es fácil de poner en práctica. Prodigy ayuda brindándole una herramienta práctica y flexible que se adapta fácilmente a su flujo de trabajo. Con pasos concretos a seguir en lugar de un objetivo vago, la anotación y la inspección de datos cambiarán de algo que debe hacer a algo que hará.

  \item[TextAE]

        TextAE de código abierto se desarrolla como un proyecto de código abierto. Publicado bajo la licencia MIT. Soporte Unicode Admite cualquier idioma compatible con UTF8. (Sin embargo, podríamos probar la función solo con un número limitado de idiomas. Si encuentra un problema con su idioma, háganoslo saber para que podamos solucionarlo). Instalación cero
        Puede utilizar un editor TextAE listo para usar inmediatamente sin ningún proceso de instalación.
        Editor de GUI con todas las funciones
        Puede crear o editar varios tipos de anotaciones. anotación de entidad nombrada anotación de relación anotaciones sintácticas visor / editor predeterminado de PubAnnotation TextAE se desarrolla como un visor / editor predeterminado de PubAnnotation.
        El cliente REST TextAE funciona como un cliente REST, lo que significa que puede obtener un archivo de anotaciones de la red y puede publicar un archivo de anotaciones en la red.

  \item[LightTag]

        Trabaje más rápido con nuestra interfaz optimizada
        Atajos de teclado
        Sin supuestos de tokenización
        Soporte completo de Unicode
        Anotaciones de subpalabras y frases
        Idiomas RTL y CJK
        Anotaciones de entidad, clasificación y relación

        Controle la calidad de sus datos
        El modo de revisión y la generación de informes de LightTag facilitan garantizar que sus datos sean perfectos y que sus anotadores estén funcionando al máximo.

        Controle la calidad de sus datos
        El modo de revisión y la generación de informes de LightTag facilitan garantizar que sus datos sean perfectos y que sus anotadores estén funcionando al máximo.

  \item[Djangology]

        La aplicación web de anotación Djangology se creó originalmente para satisfacer las necesidades de un proyecto de anotación colaborativo que involucra a más de 250 participantes internacionales. El objetivo del proyecto era crear un corpus estándar de oro que esté anotado con entidades nombradas del dominio de interés: estudios médicos de las condiciones de trauma, shock y sepsis. Resúmenes de una conferencia anual dedicada
        al sujeto y alojado por la North American Shock Society 6 se utilizaron para identificar las entidades nombradas específicas del dominio a través de un proceso automatizado. Las anotaciones de entidades nombradas tuvieron que ser validadas por expertos en el dominio, los contribuyentes a la conferencia. El sistema Djangology
        ha estado en uso durante dos años consecutivos (2008 y 2009), y ha logrado una tasa de respuesta media de los contribuyentes del 70 \%.

        Las necesidades del proyecto llevaron a un conjunto de requisitos comunes a proyectos similares de anotación colaborativa altamente distribuida. Se necesitaba una interfaz de administración para gestionar documentos y usuarios, así como para la definición de esquemas de anotación. Las anotaciones creadas mediante un proceso automatizado debían cargarse en el sistema. Los participantes fueron notificados por correo electrónico y se les presentó un enlace a la interfaz basada en web. Después de iniciar sesión, los anotadores pudieron ver una lista de documentos asignados. Se necesitaba una interfaz de usuario intuitiva basada en la web para permitir a los participantes anotar documentos con un mínimo de texto instructivo. El acceso fácil y rápido a las anotaciones fue crucial para el éxito del proyecto. Como el tiempo de los expertos en dominios es bastante valioso, las complicadas instrucciones de instalación o anotación serían prohibitivas. El sistema también necesitaba mostrar estadísticas de acuerdos interannotadores, así como la evaluación

        Djangology se puede implementar en cualquier servidor accesible desde la web y requiere una instalación de Python, una instalación de Django y conectividad a un servidor de base de datos 9. El código fuente y las instrucciones de instalación se pueden encontrar en el sitio web del proyecto\footnote{\url{http://djangology.sourceforge.net/}}. Estimamos que el tiempo de instalación y configuración de un extremo a otro para un desarrollador experto en Python y Django es de menos de una hora. Una vez implementada, se puede acceder a la aplicación desde cualquier navegador web; no se necesitan complementos de navegador, instalación de JVM o configuraciones de seguridad personalizadas, ya que la comunicación cliente-servidor se basa en solicitudes HTTP y Ajax estándar.

        El esquema de la base de datos de la aplicación (Figura 1 (a)) y la interfaz de usuario se pueden ampliar y personalizar rápidamente. Por ejemplo, la creación de un nuevo campo para las cuentas de anotador podría lograrse sin esfuerzo simplemente agregando un nuevo atributo a la clase de modelo de Python correspondiente. El formulario web correspondiente y el esquema de la base de datos subyacente se actualizan de forma transparente mediante el marco de Django

        La aplicación Djangology presenta a los administradores una interfaz para crear / modificar proyectos de anotaciones y administrar usuarios (Figura 2). Los administradores pueden importar documentos (documento único o modo por lotes) en un proyecto, definir el esquema de anotación del proyecto, crear cuentas de anotadores y asignar anotadores a proyectos específicos y a una lista de documentos. Las anotaciones y los documentos existentes también se pueden cargar fácilmente en el sistema a través de scripts Python personalizados (scripts Django independientes) o mediante una conexión directa a la base de datos Djangology. Djangology se ha utilizado para importar anotaciones creadas manualmente en formato Knowtator y desde BioScope Corpus (Szarvas et al., 2008), así como anotaciones creadas automáticamente por los marcos Gate y UIMA (Ferrucci y Lally, 2004) y el sistema Metamap c. de la Biblioteca Nacional de Medicina. En el flujo de trabajo del sistema, a los colaboradores se les suele enviar por correo electrónico la información de autenticación del sistema y se les presenta un enlace a la aplicación (Figura 3).

        Una vez que hayan iniciado sesión, los anotadores pueden seleccionar uno de sus documentos asignados y continuar con la interfaz de anotación basada en la web. Una página web basada en Ajax permite a los colaboradores resaltar un fragmento de texto y asignarlo a uno de los tipos de anotaciones predefinidos (según el esquema de anotaciones del proyecto). El procedimiento para ingresar nuevas anotaciones y modificar las existentes es intuitivo y se basa en las convenciones de la interfaz de usuario: selección de texto / selección de menú del botón derecho. El sistema está diseñado específicamente para requerir una inversión mínima de tiempo por parte de los anotadores involucrados. No es necesario instalar, configurar o leer los manuales de usuario por parte de los colaboradores. Las anotaciones se guardan en la base de datos de backend a medida que se ingresan, lo que garantiza que no se pierda ningún trabajo. Para ahorrar el esfuerzo de los anotadores, una vez que se anota una frase, todas las apariciones de la frase en el documento se anotan automáticamente en el mismo tipo. Los usuarios también tienen la posibilidad de anular las anotaciones creadas automáticamente o cambiar el comportamiento predeterminado del sistema. Si lo desea, los contribuyentes también pueden marcar los documentos como completados para alertar al administrador del proyecto sobre el progreso de la anotación.

        Una vez que se recopilan las anotaciones de varios contribuyentes, los administradores de proyectos tienen la capacidad de ver las estadísticas del acuerdo interannotador: una variedad de métricas basadas en proyectos y documentos por pares se calculan y presentan en la interfaz de usuario. Dado que el análisis de los desacuerdos entre los anotadores es una tarea común, también se proporciona una interfaz para una comparación lado a lado de las anotaciones de los documentos.

  \item[MyMiner]

        MyMiner es una aplicación web interactiva basada en un diseño modular con el propósito de ayudar a los usuarios en las tareas de biocuración y anotación de texto. La interfaz de MyMiner está diseñada para ser fácil de usar y no requiere la instalación de ningún software local. Cada módulo tiene una opción de exportación para guardar los resultados. El tiempo dedicado a procesar un documento se registra en el archivo exportado. Para mejorar la facilidad de uso, se ha adoptado y conservado un diseño de pantalla común entre los módulos de la aplicación. El área de análisis del documento de entrada se encuentra en la parte superior de la página; las opciones y herramientas se colocan debajo de la zona de selección principal. MyMiner combina PHP, JavaScript y AJAX para mejorar la interactividad del usuario. El núcleo del sistema MyMiner cubre cuatro módulos de aplicación que pueden usarse de forma independiente o combinarse siguiendo los pasos de una tubería de biocuración (Fig. S1 complementaria).

        MyMiner maneja cualquier texto sin formato, incluidos resúmenes de artículos, oraciones de documentos, términos de ontología o descripciones de enfermedades.

        El módulo "Etiquetado de archivos" es una interfaz de clasificación de texto manual fácil de usar que permite clasificar documentos, resúmenes, oraciones o términos, ofreciendo la posibilidad de ingresar etiquetas de clase especificadas por el usuario. Este módulo podría usarse, por ejemplo, para clasificar documentos como relevantes o no para un tema específico de una consulta de PubMed. Su propósito es cubrir la tarea de triaje (selección de artículos) que realizan los anotadores de la base de datos, pero también se puede utilizar para cualquier registro de clasificación manual. Los datos etiquetados que resultan de esta clasificación pueden servir como conjuntos de entrenamiento y prueba para sistemas de categorización de texto. Para reducir el tiempo de clasificación manual, ofrece la opción de establecer dinámicamente resaltados de texto positivos y negativos. Estas son expresiones que los usuarios pueden establecer en cualquier momento durante el proceso de etiquetado para resaltar el texto relevante (marcado en amarillo) o no relevante (marcado en rojo) para el tema de interés. El sistema ofrece la posibilidad de cargar las pautas de clasificación para que el anotador pueda consultarlas cuando sea necesario. Los usuarios pueden pausar y reanudar el proceso de conservación en cualquier momento guardando el documento clasificado. Para reanudar la clasificación, el archivo guardado se carga como archivo de entrada. Se registra el tiempo empleado por un usuario para seleccionar la etiqueta correspondiente. Esto puede resultar útil para estimar la eficiencia de los anotadores y la dificultad de la tarea.

        El módulo "Comparar archivo" facilita la comparación directa de colecciones de elementos etiquetados generados por varios enfoques o personas. Además, es posible crear subconjuntos a partir de estas colecciones en función del acuerdo o desacuerdo de las etiquetas de anotación. Este módulo se puede utilizar para comparar y evaluar métodos de clasificación de documentos entre varias personas o software. Muestra un resumen global con información que cubre: (i) el número de documentos dentro de cada clase; (ii) el tiempo medio necesario para clasificar el texto; (iii) la correlación entre el tiempo de clasificación y la longitud del texto o (iv) el número de elementos etiquetados de manera diferente entre los anotadores. Este módulo permite extraer una colección de textos (conocido como corpus Gold Standard) que han sido etiquetados consistentemente por todos los anotadores. Alternativamente, el módulo también se puede utilizar para extraer los casos límite etiquetados de manera diferente. Las anotaciones apresuradas / inexactas se pueden detectar por desacuerdos entre los anotadores y / o una mala correlación entre el tamaño del documento y el tiempo de clasificación. Estos casos se pueden usar para refinar y mejorar las pautas de clasificación. El módulo Comparar archivo se ha utilizado para estimar la coherencia de las anotaciones manuales entre varios individuos y métodos (Sección 2 de datos suplementarios).

        El propósito del módulo "Etiquetado de entidades" (reconocimiento de menciones de entidades) es detectar manualmente objetos conceptuales importantes dentro de un documento, un primer paso para una mayor identificación de eventos de anotación y relaciones para poblar bases de datos de conocimiento. Este módulo podría usarse para crear un corpus de menciones de genes y proteínas para probar y entrenar una herramienta de reconocimiento de entidades nombradas. Este módulo ofrece una interfaz interactiva que permite a los usuarios identificar semiautomáticamente varios tipos de entidades dentro de los documentos. Ha sido diseñado como un editor en línea WYSIWYG (What You See Is What You Get) que permite la adición de etiquetas especificadas por el usuario para nuevos tipos de entidades. Para la detección de bioentidades importantes, este módulo proporciona el reconocimiento automático de proteínas, ADN, ARN, líneas celulares y tipos de células mediante la integración del marcador ABNER (Settles, 2005). El sistema LINNAEUS se incorpora a MyMiner para identificar especies y organismos (Gerner et al., 2010). Además, las entidades definidas por el usuario se pueden detectar si se proporcionan diccionarios de términos y etiquetas. Para mejorar la precisión de las anotaciones, las etiquetas se pueden editar y las etiquetas generadas incorrectamente se pueden eliminar. Para definir relaciones simples entre entidades y términos, se agregó a este módulo una pantalla de casilla de verificación de matriz (Fig. Complementaria S14).

        El módulo "Entity Linking" facilita la anotación manual de bioentidades mencionadas en un documento con identificadores estandarizados. Este módulo podría usarse para vincular manualmente artículos a identificadores de enfermedades y proteínas para crear un catálogo de proteínas involucradas en patologías. Los nombres de genes / proteínas se reconocen automáticamente y se muestran como una lista que se puede editar manualmente, y se pueden agregar nuevas entidades y eliminar las identificadas incorrectamente. Para cada nombre de gen / proteína, MyMiner sugiere una lista clasificada de identificadores UniProt que utilizan el mecanismo de puntuación de búsqueda UniProt (Arighi et al., 2011). Las menciones de especies se normalizan a los identificadores de taxón NCBI; Los identificadores OMIM están asociados a enfermedades y los términos de ontología están vinculados a identificadores de archivos de ontología enviados. Para este propósito, MyMiner lanza consultas asincrónicas a las respectivas bases de datos (UniProt, taxonomía NCBI, OMIM y archivo de ontología proporcionado por el usuario) utilizando solicitudes AJAX. Para organismos, proteínas, enfermedades y términos de ontología, se muestra una breve descripción para ayudar a validar posibles aciertos candidatos y para ayudar durante la desambiguación manual de identificadores de bases de datos potenciales. Las casillas de verificación permiten la selección de los identificadores más apropiados de la lista de candidatos. Si las especies se especifican antes de una búsqueda de identificadores de proteínas, se aplican restricciones específicas de especies para reducir el número de candidatos potenciales de UniProt.

  \item[WAT-SL]

        WAT-SL (Herramienta de anotación web para etiquetado de segmentos), una herramienta de anotación basada en la web de código abierto dedicada al etiquetado de segmentos.1 WAT-SL proporciona todas las funcionalidades para ejecutar y administrar proyectos de etiquetado de segmentos de manera eficiente. Su interfaz de anotación autodescriptiva solo requiere un navegador web, lo que la hace particularmente conveniente para los procesos de anotaciones remotas. La interfaz se puede adaptar fácilmente a los requisitos del proyecto utilizando tecnologías web estándar para centrarse en las etiquetas de segmento específicas en cuestión y cumplir con las expectativas de diseño de los anotadores. Al mismo tiempo, asegura que los textos a etiquetar permanezcan legibles durante todo el proceso de anotación. Este proceso se basa en el servidor y se puede interrumpir en cualquier momento. El progreso del anotador se puede monitorear constantemente, ya que todas las interacciones relevantes de los anotadores se registran en un formato de texto sin formato basado en valores clave.

        WAT-SL es una herramienta de anotación basada en web lista para usar y fácilmente personalizable que se dedica al etiquetado de segmentos y que se centra en un uso fácil para todas las partes involucradas: anotadores, curadores de anotaciones y organizadores de proyectos de anotaciones. En WAT-SL, el proceso de anotación se divide en tareas, que generalmente corresponden a textos individuales. Juntas, estas tareas forman un proyecto.

        Una vez que se etiqueta un segmento, su color de fondo cambia y el botón muestra una abreviatura de la etiqueta respectiva. Para ayudar a los anotadores a formar un modelo mental de la interfaz de anotaciones, los colores de fondo de los segmentos etiquetados coinciden con los colores de las etiquetas en el menú. Todas las etiquetas se guardan automáticamente, evitando cualquier pérdida de datos en caso de cortes de energía, problemas de conexión o similares.
        En algunos casos, los textos pueden estar segmentados en exceso, por ejemplo, debido a una segmentación automática. Si este es el caso, WAT-SL permite a los anotadores marcar un segmento para continuar en el siguiente segmento. A continuación, la interfaz conectará visualmente estos segmentos (consulte los botones que muestran “->” en la Figura 2). Finalmente, la interfaz de anotaciones incluye un cuadro de texto para dejar comentarios a los organizadores del proyecto. Para simplificar la formulación de comentarios, cada segmento está numerado, y el número se muestra cuando se mueve el cursor del mouse sobre él.

        Después de que se completa un proceso de anotación, generalmente sigue una fase de curación en la que las anotaciones de diferentes anotadores se consolidan en una. La interfaz de curación de WAT-SL permite una curación eficiente al imitar la interfaz de anotación con tres ajustes (Figura 3): Primero, los segmentos para los cuales la mayoría de los anotadores acordaron una etiqueta están preetiquetados en consecuencia. En segundo lugar, el menú muestra para cada etiqueta cuántos anotadores la eligieron. Y tercero, la descripción de la etiqueta muestra (anonimizada) qué anotador eligió la etiqueta, para que los curadores puedan interpretar cada etiqueta en su contexto. Se puede acceder a la curación bajo la misma URL que la anotación para permitir que los anotadores de algunas tareas sean curadores de otras tareas.

        WAT-SL es una aplicación Java independiente de plataforma y fácil de implementar, con pocas configuraciones almacenadas en un simple archivo "clave = valor". Entre otros, los anotadores se gestionan en este archivo asignando un nombre de usuario, una contraseña y un conjunto de tareas a cada uno de ellos. Para cada tarea, el organizador de un proyecto de anotación crea un directorio (ver más abajo). WAT-SL utiliza el nombre del directorio como nombre de la tarea en todas las ocasiones. Una vez que se ejecuta el archivo Java que proporcionamos, lee todas las configuraciones e inicia un servidor. El servidor está inmediatamente listo para aceptar solicitudes de los anotadores.

\end{description}

La distribución pública de corpus anotados y recursos relacionados, por ejemplo, líneas de base, scripts de evaluación, scripts de carga y formato, etc., a menudo se habilita a través de plataformas de intercambio de código fuente abierto.
Podría decirse que las opciones más populares son Github\footnote{\url{https://github.com}} y Gitlab\footnote{\url{https://gitlab.com}}, que proporcionan características similares a pesar de pequeñas diferencias en su núcleo. modelos de negocio.
También es posible compartir los recursos correspondientes a través de plataformas de hospedaje institucional u otras soluciones ad-hoc. Esto podría ser conveniente en el caso de requisitos legales, licencias complejas que son incompatibles con idiosincrasias de código abierto o cualquier otra consideración que no permita el intercambio público completo.
En nuestro caso, todos los recursos están disponibles públicamente en una colección de repositorios de Gitlab\footnote{\url{https://ehealthkd.github.io}}.

\section{Anotación Semi-Automática}

El aprendizaje automático, y específicamente el aprendizaje supervisado, es una de las herramientas más efectivas para automatizar tareas cognitivas complejas, como reconocer objetos en imágenes o comprender texto en lenguaje natural. Uno de los principales obstáculos del aprendizaje supervisado es la necesidad de conjuntos de datos de alta calidad de muestras etiquetadas en las que se puedan entrenar modelos estadísticos. Estos conjuntos de datos generalmente son construidos por expertos humanos en un proceso manual largo y costoso. El aprendizaje activo~\cite{Cohn2010ActiveL} es un paradigma alternativo al aprendizaje supervisado convencional que se ha propuesto para reducir los costos involucrados en la anotación manual.

La idea clave que subyace al aprendizaje activo es que un algoritmo de aprendizaje puede funcionar mejor con menos ejemplos de entrenamiento si se le permite seleccionar activamente qué ejemplos aprender de~\cite{seungquery}.
En el contexto del aprendizaje supervisado, este paradigma cambia el papel del experto humano.
En contextos de aprendizaje supervisado convencionales, el experto humano guía el proceso de aprendizaje proporcionando un gran conjunto de datos de ejemplos etiquetados. Sin embargo, en el aprendizaje activo, el rol activo se traslada al algoritmo y el experto humano se convierte en un oráculo, participando en un ciclo de etiquetado-entrenamiento-consulta.
En el paradigma activo, un modelo se construye de forma incremental entrenando en una colección parcial de muestras y luego seleccionando una o más muestras sin etiquetar para consultar el oráculo humano en busca de etiquetas y aumentar el conjunto de entrenamiento.
Este enfoque introduce el nuevo problema de cómo seleccionar mejor las muestras de consulta para maximizar el rendimiento del modelo y minimizar el esfuerzo del participante humano.

El escenario de aprendizaje activo más simple consiste en la clasificación de elementos independientes $ x_i $ extraídos de un grupo de muestras sin etiquetar.
Los ejemplos van desde la clasificación de imágenes~\cite{Gal2017DeepBA} hasta la minería de sentimientos~\cite{Kranjc2015ActiveLF}, en la que el nivel mínimo de muestreo (por ejemplo, una imagen o un documento de texto) corresponde al nivel mínimo de decisión. es decir, se asigna una sola etiqueta a cada $ x_i $. Los escenarios más complejos surgen cuando el nivel de decisión es más detallado que el nivel de muestreo. En el dominio de la minería de texto, un escenario interesante es la tarea de extracción de entidades y relaciones del texto en lenguaje natural~\cite{zhang2012unified}.
En este escenario, el nivel de muestreo es una oración, pero el nivel mínimo de decisión involucra cada ficha o par de fichas en la oración y, además, estas decisiones en general no son independientes dentro de la misma oración.
En este caso, no es trivial estimar qué tan informativa será una muestra sin etiquetar, ya que cada muestra tiene varias fuentes de incertidumbre.

En esta sección se revisan algunas de las investigaciones más relevantes relacionadas con el aprendizaje activo en general, y específicamente enfocadas en la detección de entidades y extracción de relaciones.
Una de las decisiones de diseño más importantes en el aprendizaje activo es cómo seleccionar inteligentemente las nuevas muestras sin etiquetar de la manera más eficiente. El supuesto subyacente es que queremos entrenar a un
modele con el rendimiento más alto posible~(medido en precisión, $ F_1 $, etc.) mientras se minimiza el costo humano (medido en tiempo, número de muestras etiquetadas manualmente o cualquier otra métrica adecuada).
Este requisito a menudo se enmarca como la selección de las muestras sin etiqueta \textit{más informativas} y se formaliza en términos de una estrategia de consulta~\cite{seungquery}.
Las estrategias de consulta más comunes para el aprendizaje activo de propósito general se pueden agrupar en las siguientes categorías:

\begin{description}
  \item [(i) Muestreo de incertidumbre:] Las muestras más informativas se consideran aquellas con el mayor grado de incertidumbre, dada alguna medida de incertidumbre para cada muestra~\cite{Lewis1994148}.

  \item [(ii) Consulta por comité:] Las muestras más informativas se consideran aquellas con el mayor desacuerdo entre un comité de diferentes modelos o diferentes hipótesis del mismo modelo subyacente~\cite{seungquery}.

  \item [(iii) Cambio de modelo esperado:] Las muestras más informativas se consideran aquellas que producen el mayor cambio en la hipótesis del modelo si se incluyeron en el conjunto de entrenamiento~\cite{NIPS2007_3252}.

  \item [(iv) Reducción de varianza y error:] Las muestras más informativas son aquellas que producen la mayor reducción en el error de generalización del modelo o, como proxy, su varianza~\cite{roy2001toward}.
\end{description}

Las estrategias de cambio de modelo (iii) y reducción de varianza / error (iv) esperadas dependen en gran medida del modelo de aprendizaje específico utilizado.
Por el contrario, el muestreo de incertidumbre (i) y la consulta por comité (ii) son aplicables en general con un alto grado de agnosticismo del modelo.
Además, los subconjuntos relevantes de ambas estrategias se pueden formalizar bajo un solo marco si definimos la incertidumbre como una medida de la entropía de la salida prevista del modelo.
En este marco, la consulta por comité se puede implementar mediante votación ponderada, asignando así probabilidades empíricas a los posibles resultados.

La densidad ponderada es una estrategia complementaria en la que las muestras más informativas se ponderan por lo representativas que son del espacio de entrada, por ejemplo, midiendo su similitud con las muestras restantes~\cite{settles2008analysis}.
Este enfoque intenta contrarrestar una tendencia notable a seleccionar valores atípicos como las muestras más informativas, un problema asociado con otras estrategias de consulta, ya que los valores atípicos son a menudo las muestras que crean la mayor cantidad de incertidumbre, desacuerdo o cambio de hipótesis.
Recent advseplnances in natural language processing have produced an increased interest in active learning to alleviate the requirement for large annotated corpora~\cite{Olsson2009ALS, Tchoua2019ActiveLY}.
\citet{settles2008analysis} compare several strategies for active learning in sequence labeling scenarios, concluding that query strategies based on measures of sequence entropy combined with weighted sampling outperform other variants.
\citet{Meduri2020ACB} propose a comprehensive benchmark to evaluate different active learning strategies for entity matching.
In the task of named entity recognition, CRF models have been used to select query samples
\citep{Claveau2017StrategiesTS, Lin2019AlpacaTagAA}.
The task of relation extraction also benefits from active learning approaches, both in general-purpose settings~\cite{fu2013efficient} and in domain-specific settings~\cite{zhang2012unified}.
However, despite the growing body of research, it is still a challenge to apply active learning in joint entity recognition and relation extraction, especially in scenarios with low resources~\cite{Gao2019ActiveER}.

\section{Recursos Lingüísticos}

En el estado del arte se han establecido diferentes relaciones semánticas, muchas de las cuales dan lugar a la construcción de corpus. Nos enfocamos en dos enfoques: corpus o modelos de anotación para representar el conocimiento en muchos dominios, así como aquellos específicamente relacionados con la salud.
La tabla~\ref{tab:corpora} presenta las siete características relevantes para nuestro corpus e indica cuáles de ellas están presentes en una muestra de corpus del estado de la técnica.
Estas características se pueden entender en los siguientes términos:

\begin{enumerate}
  \item \textit{anotación de propósito general:} aplicabilidad del modelo de anotación subyacente a cualquier dominio;
  \item \textit{independencia de la sintaxis:} capturando aspectos semánticos en lugar de relaciones sintácticas en oraciones;
  \item \textit{conocimiento ontológico:} que apoya la herencia y la composición entre conceptos;
  \item \textit{conceptos compuestos:} permitiendo la anotación de conceptos que involucran otros subconceptos;
  \item \textit{atributos:} atributos de modelado para cada entidad anotada, como cuantificadores~(por ejemplo, número de ocurrencias) o calificadores~(por ejemplo, grado de certeza);
  \item \textit{relaciones contextuales:} relaciones de modelado que solo ocurren cuando están condicionadas por un contexto específico; y,
  \item \textit{causalidad / implicación:} incluyendo relaciones para representar causalidad y / o implicación.
\end{enumerate}

\begin{table}[htb]
  \centering
  \begin{tabular}{ll|c|c|c|c|c|c|c|c}
                                                          & \textbf{Characteristics}                                       & \rotatebox{90}{\textbf{Ixa MedGS}~\cite{ORONOZ2015318}} & \rotatebox{90}{\textbf{DrugSemantics}~\cite{moreno2017drugsemantics}} & \rotatebox{90}{\textbf{DDI}~\cite{herrero2013ddi}} &
    \rotatebox{90}{\textbf{Bio AMR}~\cite{bioamr}}        &
    \rotatebox{90}{\textbf{YAGO}~\cite{suchanek2007yago}} & \rotatebox{90}{\textbf{ConceptNet}~\cite{speer2017conceptnet}} & \rotatebox{90}{\textbf{eHealth-KD v1}~\cite{ehealth}}   &
    \rotatebox{90}{\textbf{eHealth-KD v2}}                                                                                                                                                                                                                                                                                                      \\ \midrule
    1                                                     & general-purpose annotation                                     &                                                         &                                                                       &                                                    & \ok & \ok & \ok & \ok & \ok \\
    2                                                     & independence of syntax                                         & \ok                                                     & \ok                                                                   & \ok                                                &     & \ok & \ok & \ok & \ok \\
    3                                                     & ontological knowledge                                          &                                                         &                                                                       &                                                    & \ok & \ok & \ok & \ok & \ok \\
    4                                                     & composite concepts                                             &                                                         &                                                                       &                                                    & \ok &     &     & \ok & \ok \\
    5                                                     & attributes                                                     &                                                         & \ok                                                                   &                                                    & \ok & \ok &     & \ok & \ok \\
    6                                                     & contextual relations                                           &                                                         &                                                                       &                                                    & \ok &     &     &     & \ok \\
    7                                                     & causality / entailment                                         & \ok                                                     &                                                                       &                                                    & \ok &     & \ok &     & \ok \\
    \bottomrule
  \end{tabular}
  \caption{Comparison between the \textit{eHealth-KD v2} corpus and other corpora with respect to
    the characteristics that define our proposal.}
  \label{tab:corpora}
\end{table}

\begin{table}[h!]\centering
  \footnotesize{
    \begin{tabularx}{\hsize}{X|XXXXX}
      \hline
      \hline
      \textbf{Corpus}          & \textbf{Drug Semantic} & \textbf{Ixa MedGS}         & \textbf{CLEF}           & \textbf{DDI}       & {\textbf{BARR2}}         \\
      \hline                                                                                                                                                   \\
      \textbf{Doc. Type}       & Product summaries      & Discharge summaries        & Clinical documents      & Abstracts          & Clinical case studies    \\
      \textbf{Annotation Type} & Manual                 & Auto/Manual check          & Manual                  & Auto/Manual check  & Manual                   \\
      \textbf{Annotators}      & Experts                & Experts                    & Experts \& Non-experts  & Expert             & Experts                  \\
      \textbf{Schema}          & Medical entities       & Medical entities           & Medical entities        & Medical entities   & Medical abbreviations    \\
      \textbf{Language}        & Spanish                & Spanish                    & English                 & English            & Spanish                  \\
      \textbf{Documents}       & 5~(16\%)               & 75~(0.01\%)                & 150~(0.27\%)            & 1025~(100\%)       & 648(20\%)                \\
      \textbf{Origin}          & AEMPS                  & Galdacao-Usansolo Hospital & Royal Madersen Hospital & Medline, Drug Bank & PubMed, IBCECS \& SciELO \\
      \hline
      \hline
    \end{tabularx}
  } %%% CHANGE add BARR2 corpus
  \caption{Summary of related corpora annotated with domain-specific entities for the health domain.
      {Percentage values for \textbf{Documents} indicate how many of the original documents were actually annotated, as reported by the original authors.} %%%%CHANGE explain percentages
    \label{tab:stateofart}}
\end{table}


\begin{table}[h!]\centering
  \footnotesize{
    \begin{tabularx}{\hsize}{X|XXXX}
      \hline
      \hline
      \textbf{Corpus}          & \textbf{Bio AMR} & \textbf{Yago}      & \textbf{Emotinet}             & \textbf{eHealth-KD} \\
      \hline                                                                                                                 \\
      \textbf{Doc. Type}       & Sentences        & Sentences          & Posts                         & Sentences           \\
      \textbf{Annotation Type} & Manual           & Automatic          & Manual                        & Manual              \\
      \textbf{Annotators}      & Non-experts      & Non-experts        & Non-experts                   & Non-experts         \\
      \textbf{Schema}          & AMR              & {SPO}              & {SAOE}                        & {SAT+R}             \\ %%%% CHANGE add basic semantic relations
      \textbf{Language}        & English          & English            & Spanish \& English \& Italian & Spanish             \\
      \textbf{Documents}       & 6542             & -----              &                               & 1173(11.8\%)        \\
      \textbf{Origin}          & PubMed           & Wikipedia, WordNet & Blog                          & Medline Spanish XML \\
      \hline
      \hline
    \end{tabularx}
  }
  \caption{Summary of related corpora annotated with a general-purpose schema, or not specific to the health domain.
      {Percentage values for \textbf{Documents} indicate how many of the original documents were actually annotated, as reported by the original authors. SPO: Subject, Predicate, Object triplets; SAT+R: Subject, Action, Target triplets and additional Relations; SAOE:  Subject, Action, Object, Emotion tuples.}
    \label{tab:stateofart2}}
\end{table}

\subsection{Descripción de los recursos}

\begin{description}
  \item[Ixa MedGS]

  Consiste en resúmenes de alta anotados sintáctica y semánticamente escritos en español espontáneo por médicos. El objetivo es utilizar este corpus para desarrollar herramientas de anotación automática y, por lo tanto, facilitar a los médicos la recuperación de información de las HCE. Los datos — historias clínicas electrónicas recogidas en el Hospital Galdakao-Usansolo — fueron objeto de un convenio entre el Servicio Vasco de Salud y la Universidad del País Vasco, en el que el Servicio de Salud facilitó un corpus totalmente despojado de datos identificativos de carácter personal y autorizó su uso. exclusivamente con fines de investigación.

  El corpus se centra en los Efectos Adversos (EA), que el informe ENEAS [8] —estudio nacional sobre Efectos Adversos asociados a la hospitalización publicado por el Ministerio de Sanidad y Consumo español— define de la siguiente manera: un accidente o incidente que haya herido o pueda ha lesionado al paciente durante el tratamiento. Entre los diferentes EA que se distinguen en el informe, la gran mayoría está relacionada con una de las siguientes tres causas: (i) prescripción de medicamentos (37,4\% de todos los EA); (ii) infecciones nosocomiales (25,3\% de todos los EA); y (iii) procedimientos (25,0\% del total de EA). Nuestro trabajo se concentra especialmente en las reacciones adversas a los medicamentos (RAM), definidas como trastornos inevitables o difíciles de evitar, con o sin lesión, que se producen cuando los medicamentos se utilizan de forma adecuada [8]. Los resultados y conclusiones del informe ENEAS se presentaron en [9]: se estudiaron veinticuatro hospitales españoles para determinar el impacto y la prevenibilidad de los EA. De los EA asociados con el uso de medicamentos (37,4\% de todos los EA), el 34,8\% se clasificaron como prevenibles.

  \item[DrugSemantics]

  una colección de resúmenes de las características del producto en español. Se anotó manualmente con entidades con nombre farmacoterapéutico, que se detallan en el esquema de anotaciones de DrugSemantics. Los anotadores fueron una Enfermera Registrada (RN) y dos estudiantes de la Licenciatura en Enfermería. La calidad del corpus de DrugSemantics se evaluó midiendo su fiabilidad de anotación (F general = 79,33\% [IC 95\%: 78,35–80,31]), así como su precisión de anotación (global [IC 95\%: 94,11–95,19]). Además, el proceso de construcción estándar de oro se describe en detalle. En total, nuestro corpus contiene más de 2000 entidades con nombre, 780 oraciones y 226,729 tokens. Por último, se presenta un módulo de Clasificación de Entidades Nombradas capacitado en DrugSemantics con el objetivo de mostrar la calidad de nuestro corpus, así como un ejemplo de cómo usarlo.

  \item[DDI]

  which is annotated with pharmacological substances as well as the interactions between them. The DDI corpus is the first corpus which includes pharmacodynamic (PD) and pharmacokinetic (PK) DDIs. A PD DDI occurs when the pharmacological effects of one drug are modified by the presence of another drug, while a PK DDI is the result from the interference of drug absorption, distribution, metabolism and/or elimination of a drug by another drug. While there are several annotated corpora with biological entities and their relationships (see Section 2), the shortage of annotated corpora for DDI extraction is the main bottleneck in the development of NLP systems for this area of Pharmacovigilance.

  The DDI corpus has been developed for the DDI Extraction 2013 challenge (http://www.cs.york.ac.uk/semeval-2013/task9/), whose main goal is to provide a common framework for the evaluation of information extraction techniques applied to the recognition of pharmacological substances and the detection of DDIs from biomedical texts. For this purpose, two substasks have been proposed: the recognition and classification of drug names and the extraction and classification of their interactions.

  Based on the sentence splitting during preprocessing, the DDI-DrugBank corpus contains 6795 sentences, and the DDI-MedLine corpus is made up of 2147 sentences. Table 2 shows the number of the named entity types annotated in each corpus. The most common type was drug (63\%) in both corpora. However, the numbers of other types of entity differ between both sub-corpora. For example, while the second most common type in the DDI-MedLine corpus was drug-n (23\%), these substances hardly ever occur in the DDI-DrugBank corpus. As regards relationships, Table 3 shows the numbers of the annotated relationships in each corpus. Effect was the dominant relationship found in the whole DDI corpus. Advice, accounting for 20.9\% of the whole relationship, showed an even greater disproportion between both corpora because the ratio of relationship being advice interactions in the DDI-DrugBank corpus (22\%) is much higher than in the DDI-Medline corpus (5\%).

  \item[Bio AMR]

  Este corpus incluye anotaciones de artículos de PubMed relacionados con el cáncer, que cubren 3 artículos completos (PMID: 24651010, PMID: 11777939, PMID: 15630473), así como las secciones de resultados de 46 artículos adicionales de PubMed. El corpus también incluye alrededor de 1000 oraciones, cada una del corpus de entrenamiento BEL BioCreative y del Chicago Corpus.

  \item[YAGO]

  Datos de YAGO: - Entrada: infoboxes de Wikipedia, WordNet (y GeoNames en versiones posteriores) - Salida: KG con 1 millón de entidades y 5 millones de hechos (2007) → KG con 350K tipos de entidades, 10M entidades, 120M hechos (2016) Thomas Rebele, Fabian M. Suchanek y col. al, ISWC 2016– Información temporal y espacial

  Contribuciones clave: - Rich Ontology: vinculación de categorías de Wikipedia a WordNet - Alta calidad: extracciones de alta precisión (~ 95 \%) • Otras contribuciones: - YAGO es decidible, extensible y compatible con RDFS

  YAGO surgió por la necesidad de crear una ontología más grande utilizando las ontologías existentes actualmente, sus principales objetivos eran: • Unificación de Wikipedia y WordNet. • Hacer uso de estructuras e información ricas, tales como: Infoboxes, Category Pages, etc. • Asegurar la plausibilidad de los hechos a través de comprobación de tipo

  Estructura del modelo de representación en YAGO: - Modelo de datos: extensión a RDFS, incluye transitividad acíclica (atr) .– Entidades: objetos ontológicos abstractos, con las siguientes propiedades: Cada entidad es parte de al menos una clase, Clases ordenadas en jerarquía taxonómica , Las relaciones son entidades (expresan la transitividad de las relaciones - atr), Los hechos son el triple: entidad, relación, entidad, Cada hecho tiene un identificador.

  \item[ConceptNet]

  ConceptNett es un proyecto de representación del conocimiento, que proporciona un gran gráfico semántico que describe el conocimiento humano general y cómo se expresa en lenguaje natural. El alcance de ConceptNet incluye palabras y frases comunes en cualquier lenguaje humano escrito. Proporciona un amplio conjunto de conocimientos previos que debe conocer una aplicación informática que trabaja con texto en lenguaje natural. Estas palabras y frases se relacionan a través de un dominio abierto de predicados, que describen no solo cómo se relacionan las palabras por sus definiciones léxicas, sino también cómo se relacionan a través del conocimiento común. Por ejemplo, su conocimiento sobre el “jazz” incluye no solo las propiedades que lo definen, como IsA (jazz, género musical); También incluye hechos incidentales como
  • AtLocation (jazz, nueva orleans)
  • Usado para (saxofón, jazz) y
  • toca percusión en (batería de jazz, jazz).

  ConceptNet se originó como una representación del conocimiento recopilado por el proyecto Open Mind Common Sense (Singh et al., 2002), que utiliza un sitio web interactivo de larga duración para recopilar nuevas declaraciones de los visitantes del sitio y les hace preguntas específicas sobre afirmaciones que cree que pueden ser ciertas. Los lanzamientos posteriores incluyeron conocimientos de sitios web similares en otros idiomas, como portugués y holandés, y colaboraciones con juegos de palabras en línea que recopilan automáticamente conocimientos generales, lo que proporciona más conocimientos en inglés, japonés y chino.

  ConceptNet proporciona una base de conocimiento del mundo real para una variedad de proyectos y aplicaciones de IA. Se han utilizado versiones anteriores de ConceptNet (Havasi et al., 2007), por ejemplo, para construir un sistema para analizar el contenido emocional del texto (Cambria et al., 2010), para crear un sistema de diálogo para mejorar las especificaciones del software (Korner y Brumm, 2009), para reconocer las actividades de la vida diaria (Ullberg et al., 2010), para visualizar temas y tendencias en un corpus de texto no estructurado (Speer et al., 2010), y para crear exhibiciones de información pública mediante la lectura de texto. sobre personas y proyectos desde una base de conocimiento (Havasi et al., 2011).

  ConceptNet proporciona una combinación de características que no están disponibles en otros proyectos de representación del conocimiento: • Sus conceptos están conectados a palabras y frases en lenguaje natural que también se pueden encontrar en texto libre. • Incluye no solo definiciones y relaciones léxicas, sino también las asociaciones de sentido común que la gente común hace entre estos conceptos. Sus fuentes varían en formalidad desde diccionarios hasta juegos en línea. • Los conceptos no se limitan a un solo idioma; pueden ser de cualquier idioma escrito. • Integra conocimientos de fuentes con distintos niveles de granularidad y distintos registros de formalidad, y los pone a disposición a través de una representación común. ConceptNet tiene como objetivo contener tanto hechos específicos como el desordenado e inconsistente mundo del conocimiento de sentido común. Para comprender verdaderamente los conceptos que aparecen en un texto en lenguaje natural, es importante reconocer las relaciones informales entre estos conceptos que forman parte del conocimiento cotidiano, que a menudo están infrarrepresentados en otros recursos léxicos. WordNet, por ejemplo, puede decirle que un perro es un tipo de carnívoro, pero no que es un tipo de mascota. Puede decirle que un tenedor es un utensilio para comer, pero no tiene ningún vínculo entre tenedor y comer para indicarle que se usa un tenedor para comer. Agregar conocimiento de sentido común crea muchas preguntas nuevas. ¿Podemos decir que “un tenedor se usa para comer” si un tenedor se usa para otras cosas además de comer, y otras cosas se usan para comer? ¿Debemos asegurarnos de distinguir el utensilio para comer de la bifurcación de un camino? ¿Sigue siendo cierta la afirmación en culturas que suelen utilizar palillos en lugar de tenedores? Podemos intentar recopilar representaciones que respondan a estas preguntas, mientras aceptamos pragmáticamente que gran parte del contenido de una base de conocimiento de sentido común las dejará sin resolver.

  \item[CLEF]

  Este, el séptimo año del laboratorio de evaluación (y el octavo año del taller), con el objetivo de aprovechar los enfoques de evaluación y desarrollo de recursos de los seis o siete años anteriores de CLEF eHealth [8,9,14,16,26,28 , 29], ofreció las dos tareas siguientes [15]: Tarea 1. Extracción de información multilingüe: Clasificación internacional de enfermedades, versión 10 (ICD-10) codificación de resúmenes no técnicos (NTS) de experimentos con animales en alemán [22] y Tarea 2. Revisiones asistidas por tecnología (TAR) en Medicina empírica en inglés [13].

  La tarea de Extracción de información multilingüe desafió a los participantes a indexar los NTS alemanes de experimentos con animales con la terminología de enfermedades de la CIE-10. Un análisis detallado basado en las enfermedades abordadas por los NTS permite una mayor transparencia de los experimentos con animales que están llevando a cabo los investigadores [2]. Podría tratarse como una clasificación de texto o como una tarea de normalización y reconocimiento de entidades nombradas en cascada. Aunque solo abordamos un idioma (alemán), alentamos a los participantes a explorar enfoques multilingües. Los resultados de los sistemas de alto rendimiento podrían utilizarse dentro del flujo de trabajo de los institutos encargados por la Unión Europea (UE) de publicar los NTS aprobados en sus estados. La Tarea 1 de 2019 se basó en las tareas de extracción de información de 2016-2018 [19-21], que ya abordó la terminología de la CIE-10 para codificar las causas de muerte a partir de un corpus de informes de defunción en francés (2016, 2017 y 2018), inglés (2017), húngaro (2018) e italiano (2018). Previo a esto, las tareas de eHealth de CLEF consideraron el Sistema Unificado de Lenguaje Médico (UMLS) y Sistematizaron 3. Los organizadores piden disculpas a los equipos que registraron su interés en la tarea por las molestias ocasionadas por este retraso.

  Descripción general del Laboratorio de evaluación de eHealth de CLEF 2019

  Nomenclatura de medicina: codificación de términos clínicos (SNoMed-CT) de informes clínicos en inglés en 2013, y reconocimiento de entidades nombradas UMLS de informes clínicos en francés en 2015, entre otros [27]. La tarea TAR fue una tarea de RI de alta recordación en inglés que tenía como objetivo evaluar algoritmos de búsqueda que buscan identificar todos los estudios relevantes para realizar una revisión sistemática en medicina empírica. Los resultados de los enfoques explorados en los sistemas presentados para generar una visión general clara del consenso científico actual podrían estar informando la atención médica y su formulación de políticas en el futuro. Este generador automatizado podría liberar tiempo a los científicos y asesores de políticas del laborioso proceso iterativo actual de realizar búsquedas de publicaciones y revisarlas para recuperar todos los documentos que son relevantes para la redacción de revisiones sistemáticas confiables; Este difícil desafío se conoce en el dominio de las relaciones internacionales como el problema de la recuperación total y con el número de artículos médicos publicados que se expanden rápidamente, la necesidad de automatización en este proceso se vuelve de suma importancia.

  La Tarea 2 de este año se diferenció de los dos últimos años [11, 12] al diversificar el enfoque en diferentes tipos de revisiones que incluyen Exactitud de la prueba de diagnóstico (DTA), Intervención, Pronóstico y Revisiones cualitativas. Aunque la búsqueda en el área de revisiones de DTA generalmente se considera la más difícil [18], este año queríamos investigar cómo la tecnología que se ha desarrollado durante los últimos dos años se extendería a otros tipos de revisiones. El proceso típico de búsqueda de publicaciones científicas para realizar una revisión sistemática consta de tres etapas: (a) especificar una serie de criterios de inclusión que caracterizan los artículos relevantes para la revisión y construir una consulta booleana compleja para expresarlos, (b) seleccionar el resúmenes y títulos que resulten de la consulta booleana, y (c) leer y filtrar los documentos completos que pasaron la revisión de resumen y título. Sobre la base de la tarea de 2017, que se centró en la segunda etapa del proceso, es decir, la selección de resumen y título, y al igual que la tarea de 2018, la tarea de 2019 se centró tanto en la primera etapa (subtarea 1) como en la segunda etapa (subtarea 2 ) del proceso, es decir, búsqueda booleana y selección de resumen y título. Más precisamente, estas subtareas de la Tarea 2 se definieron de la siguiente manera:

  Subtarea 1. Antes de construir una consulta booleana, los investigadores deben diseñar y escribir un protocolo de búsqueda que, por escrito y en detalle, defina lo que constituye un estudio relevante para su revisión. Para el desafío asociado con la primera etapa del proceso, los participantes recibieron las piezas relevantes de un protocolo, en un intento de completar la búsqueda de manera efectiva y eficiente sin pasar por la construcción de la consulta booleana.

  Subtarea 2. Dados los resultados de la búsqueda booleana de la etapa 1 como punto de partida, se pidió a los participantes que clasificaran el conjunto de resúmenes (A). La tarea tenía los siguientes dos objetivos: (i) producir un ordenamiento eficiente de los documentos, de modo que todos los resúmenes relevantes se recuperen lo antes posible, y (ii) identificar un subconjunto de A que contenga todos o tantos de los resúmenes relevantes para el menor esfuerzo (es decir, el número total de resúmenes a evaluar).

  La tarea Consumer Health Search se anunció como una continuación de las tareas anteriores de CLEF eHealth IR que se ejecutaban todos los años desde el inicio de L. Kelly et al. Los laboratorios de evaluación de eHealth de CLEF en 2013 [5–7,10,23,25,30], y abrazaron el proceso de evaluación al estilo Text REtrieval Conference (TREC), con una colección compartida de documentos de búsqueda y sus consultas de búsqueda, la contribución de las ejecuciones de los participantes, y la posterior formación de evaluaciones de relevancia y evaluación de las presentaciones de estos participantes. Por primera vez, las consultas de búsqueda (y sus variantes) estaban destinadas no solo a estar en formato escrito sino también en formato hablado, con transcripciones automáticas de voz a texto. La nueva colección de documentos introducida en la Tarea 3 de 2018, que consta de más de 5 millones de páginas de la World Wide Web (WWW), se utilizaría para esta tarea. Esta fue una compilación de páginas web de dominios seleccionados adquiridos de CommonCrawl4. Las historias de usuario para la consulta de búsqueda y la generación de variantes de consulta fueron aquellas que, utilizando los resúmenes de descarga y las publicaciones del foro, usamos en años anteriores de la tarea.

  \item[BARR2]

  Se utilizó un subgrupo de la colección de documentos BARR2 para construir un conjunto de entrenamiento y prueba etiquetado manualmente. Seleccionamos cuidadosamente 684 casos clínicos de SciELO España, que distribuimos de la siguiente manera: 318 casos clínicos para el conjunto de entrenamiento, 146 para el conjunto de desarrollo y 220 para el conjunto de prueba. La Tabla 1 proporciona una descripción estadística de estos conjuntos de datos, que cubre las estadísticas básicas del corpus. El etiquetado manual de las menciones de abreviaturas del corpus se realizó utilizando una versión personalizada de Annotator. Luego, se utilizó el kit de herramientas de anotación Brat para revisar manualmente las anotaciones de menciones y anotar las relaciones entre las formas cortas y sus correspondientes formas largas, así como las menciones anidadas. Annotator7 es una biblioteca para anotaciones de texto en navegadores que proporciona un conjunto de herramientas interoperables para anotar contenido en páginas web. Brat8 [11] es otra herramienta intuitiva basada en web para la anotación de texto para una variedad de tareas de PNL. A diferencia de Annotator, Brat ofrece la posibilidad de anotar relaciones entre diferentes entidades.

  Para que el proceso de anotación sea lo más flexible posible, los anotadores tuvieron acceso al artículo completo del caso clínico para encontrar sus significados mencionados explícitamente en otras secciones. También utilizaron varios diccionarios biomédicos españoles de abreviaturas y acrónimos. Además, aplicamos un algoritmo automático de detección de pares de abreviaturas-definiciones [10] para detectar diferentes pares en el texto completo, por lo que los anotadores no necesitaban leer todo el artículo buscando definiciones explícitas, a menos que fuera necesario. También utilizamos una base de datos interna de pares de abreviaturas y definiciones en español10 para asignar definiciones a las abreviaturas sin definiciones explícitas.

  El corpus creado para el track estuvo compuesto por diferentes casos clínicos de acceso abierto redactados en español. Los expertos en el dominio anotaron las abreviaturas presentes en estos informes, junto con su definición. Los resultados del acuerdo entre los anotadores mostraron que los anotadores estuvieron de acuerdo con el 88 \% de los casos etiquetados, y concluyeron que las directrices que utilizaron estaban claramente estructuradas. Examinando cuáles son los tipos de abreviaturas más frecuentes, observamos que muchas de ellas corresponden a unidades de medida (clave para la detección de posología y posología), entidades anatómicas, marcadores bioquímicos y tratamientos. Al observar el idioma de las definiciones de abreviaturas, solo alrededor del 68 por ciento correspondió a definiciones en español, el resto donde la mayoría de las definiciones en inglés a menudo se relacionan con sustancias, tratamientos y entidades bioquímicas. Mapeamos manualmente 500 definiciones a SNOMED. El examen de la clase de concepto correspondiente mostró que la mayoría correspondía a la clase de sustancia.

  \item[Emotinet]

  La idea general detrás de nuestro enfoque es modelar situaciones como cadenas de acciones y su correspondiente efecto emocional utilizando una representación ontológica. Según la definición proporcionada por Studer et al. [33], una ontología captura el conocimiento compartido por una comunidad que se puede compartir fácilmente con otras comunidades. Estas dos características son especialmente relevantes si queremos aumentar el recuerdo de nuestro enfoque. El conocimiento gestionado en nuestro enfoque debe ser compartido por una gran comunidad y también debe ser alimentado por fuentes heterogéneas de conocimiento común para evitar incertidumbres. Sin embargo, se pueden introducir afirmaciones específicas para dar cuenta de las especificidades de los individuos o contextos. De esta manera, podemos modelar la interacción de diferentes eventos en el contexto en el que tienen lugar y agregar mecanismos de inferencia para extraer conocimiento que no está explícitamente presente en el texto. También podemos incluir conocimientos sobre los criterios de valoración relacionados con diferentes conceptos encontrados en otras ontologías y bases de conocimiento (para dar cuenta de las diferentes propiedades del actor, acción y objeto). Al mismo tiempo, podemos definir las propiedades de las emociones y cómo se combinan. Este enfoque puede dar cuenta de las diferencias en la interpretación, ya que el conocimiento específico sobre las creencias o preferencias individuales puede agregarse fácilmente como cadenas de acción o propiedades de los conceptos.

  Ante estos requerimientos, nuestro enfoque define una nueva base de conocimiento, denominada EmotiNet, para almacenar cadenas de acción y sus correspondientes etiquetas emocionales de diversas situaciones de tal manera que seremos capaces de extraer patrones generales de valoración. Desde un punto de vista más práctico, nuestro enfoque define una cadena de acción como una secuencia de vínculos de acción, o simplemente acciones que desencadenan una emoción en un actor. Cada vínculo de acción específico se puede describir con una tupla (actor, tipo de acción, paciente, reacción emocional).

\end{description}

La mayoría de los corpus relacionados con la salud se anotan utilizando entidades relacionadas con la salud autodefinidas relevantes para la tarea en cuestión. De estos, posiblemente uno de los más utilizados es el corpus CLEF~\cite{kelly2016overview}. Este corpus contiene 150 documentos clínicos en inglés, anotados manualmente por un equipo de expertos (clínicos y biólogos) y no expertos. Por el contrario, el corpus DDI~\cite{herrero2013ddi}, que contiene 1025 documentos en inglés de Medline, fue previamente anotado automáticamente y luego revisado manualmente por expertos del dominio (farmacéuticos). Existen corpus similares en idioma español. El corpus de Semántica de Drogas~\cite{moreno2017drugsemantics} es un ejemplo, donde los expertos del dominio (enfermeras registradas y estudiantes) anotaron manualmente resúmenes en español de las características del producto. {Asimismo, el BARR2}~\cite{barr2} {corpus contiene pares de abreviaturas y definiciones anotados manualmente en artículos clínicos españoles extraídos de bases de datos bibliográficas.}

Por otro lado, el corpus de Ixa MedGS~\cite{oronoz2015creation} fue previamente anotado automáticamente y luego revisado manualmente por expertos del dominio en Farmacología. Una alternativa interesante es el corpus de Bio AMR~\cite{bioamr, bioamrpaper}, que contiene anotaciones de AMR de varios documentos médicos, por lo que combina un esquema de anotación de propósito general en un dominio específico.

En el contexto del conocimiento del dominio general, uno de los recursos más relevantes para nuestra investigación es YAGO~\cite{suchanek2007yago}
Consiste en una gran base de conocimientos extraída automáticamente de Wikipedia, WordNet y otras fuentes. Dado que YAGO está destinado a representar el conocimiento de dominio general, su estructura semántica se define en términos de triples de hechos, en el espíritu de RDF y otras representaciones ontológicas.
En contraste, la base de conocimiento de Emotinet~\cite{Balahur2011} está orientada hacia un dominio específico (emociones), y se construye a partir de la anotación manual de entradas de blog, utilizando una estructura semántica general que vincula entidades, acciones y emociones.
Aunque Emotinet está diseñado para un dominio en particular, su estructura es bastante general, en el sentido de que puede representar fácilmente cualquier tipo de evento o acción realizada por entidades. Como muestra la Tabla \ref{tab:stateofart}, el tipo de documentos utilizados es muy variable, lo que provoca grandes diferencias en cuanto a la extensión de los documentos, la estructura del discurso y el vocabulario. Una característica interesante es el tipo de anotación, ya sea manual, pre-automatizada con revisión de expertos o totalmente automatizada. Aunque investigaciones recientes muestran una tendencia creciente hacia la anotación pre-automatizada o totalmente automatizada, la anotación manual todavía se considera más confiable. La anotación manual todavía se considera más confiable.

Los corpus relacionados con la salud suelen ser anotados por expertos con una estructura semántica de dominio específico, como entidades relacionadas con enfermedades, fármacos, genes o tratamientos. Dada la complejidad de los conceptos en el dominio médico, los anotadores suelen incluir médicos u otros especialistas del dominio médico. En estos recursos, se utilizan muy pocas características del lenguaje natural de propósito general. Esto proporciona un mayor detalle de la información semántica, ya que las entidades y relaciones son relevantes para el dominio en cuestión. Sin embargo, en el mismo sentido, podría descartar información importante en el texto que no se puede representar con la estructura definida. Esto puede o no ser un problema para una línea de investigación específica. En nuestro caso, consideramos importante extraer el mayor conocimiento posible de cada fuente. Por el contrario, los corpus o bases de conocimiento de propósito general suelen ser anotados por no expertos con una estructura semántica diseñada para representar tanto conocimiento como sea posible. Esta estrategia tiende a aumentar la memoria (se extrae una mayor cantidad de hechos) pero puede extraer hechos irrelevantes o incorrectos. En estos casos, el esquema de anotación se basa en gran medida en la semántica del lenguaje natural, como las triples Sujeto-Predicado-Objeto.

La tendencia de representar el conocimiento con una estructura general se ha visto favorecida por los avances recientes en Teleologías~\cite{teleologies} que proporcionan un marco teórico para representar hechos de propósito general utilizando un pequeño conjunto de conceptos (objetos, acciones y funciones). A diferencia de la Representación de significado abstracto (AMR), el marco de Teleologías no está dirigido específicamente a la comprensión del lenguaje natural, sino a representar la semántica de un dominio de conocimiento general. Este tipo de marco depende menos de las características lingüísticas de un idioma específico. La estructura Sujeto-Acción-Destino definida en este artículo se basa en una simplificación de la conceptualización de Teleologías, aplicada al dominio de los textos médicos. Sin embargo, inspirados en bases de conocimiento de propósito general, también incluimos algunas relaciones semánticas específicas que se utilizan ampliamente en ontologías de propósito general y redes semánticas. Esta combinación (es decir, SAT + R) hace que el esquema de anotación utilizado en eHealth-KD sea novedoso.

\subsection{Características generales}

\paragraph{Anotación de propósito general}

Los modelos de anotación de propósito general se utilizan a menudo en corpus extraídos de fuentes enciclopédicas, como \textit{YAGO}~\cite{suchanek2007yago} y \textit{ConceptNet}~\cite{speer2017conceptnet}, los cuales contienen datos extraídos automáticamente de Wikipedia.~(entre otras fuentes). Por el contrario, los modelos de anotaciones de dominios específicos se suelen emplear cuando la fuente está más restringida a un dominio específico. Los ejemplos incluyen \textit{Ixa MedGS}~\cite{ORONOZ2015318}, que contiene conceptos relacionados con la salud para enfermedades, causas y medicamentos; \textit{DrugSemantics}~\cite{moreno2017drugsemantics}, que anota entidades de salud, medicamentos y procedimientos; y \textit{DDI}~\cite{herrero2013ddi}, que anota las interacciones fármaco-fármaco. Un término medio es el corpus \textit{Bio AMR}~\cite{bioamr}, que aplica un modelo de anotación de propósito general~(AMR)~\cite{banarescu2013abstract} a los documentos de salud. El corpus \textit{eHealth-KD v2} es similar a este último en este aspecto, ya que el modelo de anotación definido es general, pero se aplica específicamente a las oraciones de salud en esta investigación.
El corpus \textit{eHealth-KD v2} constituye el resultado de la evolución del corpus \textit{eHealth-KD v1}~\cite{ehealth}.

La mayoría de los recursos mencionados se centran en capturar la semántica de las oraciones, en el sentido de que es probable que se anoten de manera similar oraciones muy diferentes con los mismos hechos. Consideramos que \textit{BioAMR} es menos independiente de la sintaxis porque aunque AMR es un modelo de anotación semántica --- mucho más abstracto que el análisis de dependencia, por ejemplo ---, todavía se basa en gran medida en la estructura gramatical de las oraciones. Por lo tanto, es probable que un cambio significativo en la estructura de la oración cambie la anotación, incluso si el mensaje semántico subyacente permanece sin cambios. Por ejemplo, dado que AMR usa roles PropBank~\cite{propbank}, cambiar una palabra por una palabra semánticamente similar, incluido un sinónimo, probablemente cambiará la anotación correspondiente y, por lo tanto, los roles disponibles.
Esto también hace que AMR y recursos similares dependan del idioma, no solo en la práctica dada su dependencia de la existencia de bancos de palabras, sino también en la naturaleza. Al intentar aplicar AMR en español, \citet{migueles2018annotating} muestra que aunque AMR es teóricamente independiente del idioma, las pautas de anotaciones existentes están sesgadas hacia el inglés y deben adaptarse para capturar fenómenos lingüísticos que no existen en inglés.
El modelo de anotación diseñado en esta investigación para el corpus \textit{eHealth-KD v2}, intenta lograr un mayor nivel de independencia sintáctica, en parte mediante el uso de un conjunto más pequeño de entidades, relaciones y roles que AMR. Más específicamente, nuestro modelo de anotación no distingue roles semánticos para cada posible \texttt{Acción}, sino que se basa en roles de propósito general~(es decir, \texttt{asunto} y \texttt{objetivo}).

\paragraph{Conocimiento ontológico}
Los modelos de anotación de propósito general a menudo permiten representar el conocimiento ontológico en forma de herencia y composición entre conceptos. En este contexto, consideramos la capacidad de reconocer y anotar estas relaciones ontológicas en el texto fuente. Los modelos de anotación relacionados con la salud no suelen abordar este problema, principalmente porque las entidades y relaciones a anotar forman una ontología predefinida donde la composición y jerarquía, si existe, ya están concebidas en el propio modelo de anotación. Sin embargo, las anotaciones de propósito general a menudo incluyen relaciones como \textit{ConceptNet} \texttt{is-a} o \texttt{part-of} que representan directamente estos conceptos ontológicos y, por lo tanto, pueden extraer representaciones ontológicas del texto natural.

\paragraph{Conceptos compuestos}

El modelo diseñado para el corpus \textit{eHealth-KD v2} también incluye relaciones específicamente para este propósito, principalmente inspiradas en \textit{ConceptNet} y \textit{YAGO}.
Los conceptos compuestos, por el contrario, se refieren a la capacidad de anotar conceptos que están formados por una combinación fina de otras entidades, en la misma oración. Por ejemplo, tome la oración: `` \textit{a los médicos que trabajan en el turno de noche se les pagan horas extra} ''. \textit{AMR} permite la representación del concepto de que no todos los médicos, sino solo aquellos que trabajan en el turno de noche, son los que cobran horas extra. Nuestra propuesta también incluye varios patrones de anotación para hacer frente a este tipo de escenarios.

\paragraph{Atributos}

Los atributos se utilizan a menudo para refinar aún más el significado de las entidades anotadas. Los ejemplos incluyen cuantificadores en \textit{AMR} o modificadores que especifican un grado de incertidumbre o una negación de un concepto. Nuestra propuesta incluye cuatro atributos de propósito general que modelan la incertidumbre, la negación y los calificadores para expresar el énfasis.

\paragraph{Relaciones contextuales}

Las relaciones contextuales, como se definen en el corpus \textit{eHealth-KD v2}, permiten hechos que solo ocurren
bajo ciertas condiciones para ser representado, por ejemplo, en un marco de tiempo o lugar específico o bajo ciertos supuestos. Esto permite una anotación semántica más detallada. \textit{BioAMR} hereda esta habilidad de \textit{AMR}, que permite modificadores para expresar \textit{cómo}, \textit{cuándo}, \textit{dónde} o \textit{por qué} ocurre algún evento. En nuestra propuesta, proporcionamos relaciones contextuales que especifican el tiempo y la ubicación, y una relación adicional de propósito general para otras condiciones.

\paragraph{Causalidad y vinculación}

La causalidad y la implicación son relaciones de propósito general que permiten cierto nivel de inferencia o razonamiento. El corpus \textit{Ixa MedGS} define una relación \texttt{causas}, ya que es relevante en el dominio que el corpus está modelando. Asimismo, \textit{AMR} y \textit{ConceptNet} incluyen relaciones similares. Nuestra propuesta incluye tanto la causalidad como la implicación como dos relaciones diferentes con significados semánticos bien definidos.

\section{Sistemas de Aprendizaje Automático para el Descubrimiento de Conocimiento}

En los últimos años, investigadores en campos como el aprendizaje automático, el descubrimiento de conocimientos, la minería de datos y el procesamiento del lenguaje natural, entre otros, han producido muchos enfoques y técnicas para aprovechar la gran cantidad de información en Internet para una variedad de tareas, desde la creación de búsquedas.~\cite{google} y sistemas de recomendación~\cite{youtube} para mejorar los diagnósticos médicos~\cite{watson}.

Entre los diferentes enfoques relevantes para el descubrimiento del conocimiento, podemos reconocer un espectro continuo de técnicas, basado en cuánto conocimiento experto se utiliza. Las técnicas fuertemente basadas en el conocimiento se basan en reglas definidas en bases de conocimiento elaboradas a mano por expertos en el dominio~\cite{chandrasekaran1986generic}. Estos enfoques tienen un alto grado de confiabilidad y precisión, y generalmente permiten una mayor complejidad en el conocimiento extraído, pero son difíciles de escalar a grandes cantidades de datos. Por el contrario, los enfoques estadísticos consisten en técnicas basadas en el reconocimiento de patrones con modelos estadísticos y probabilísticos~\cite{kevin2012machine}. Estas técnicas escalan mejor con grandes cantidades de datos~\cite{le2013building}, proporcionando una mejor recuperación, pero a menudo se limitan a extraer modelos simples de conocimiento y pueden ser más sensibles a información ruidosa, falsa o sesgada~\cite{bolukbasi2016man}.

Dadas estas características mutuamente complementarias, se han propuesto varios enfoques híbridos. Recientemente, han surgido áreas de investigación como el aprendizaje de ontología~\cite{cimiano2009ontology}, el aprendizaje mediante la lectura~\cite{barker2007learning} o la incorporación de entidades~\cite{hu2015entity}.
En estas áreas, los investigadores combinan técnicas del aprendizaje automático, el procesamiento del lenguaje natural y la representación del conocimiento para resolver problemas más complejos que no se pueden abordar utilizando solo las herramientas clásicas.

Muchos sistemas de aprendizaje automático están diseñados para resolver una tarea específica de un dominio, como asignar una clase a un elemento de un conjunto predefinido de etiquetas. Estos sistemas, cuando se entrenan con datos para un dominio en particular, a menudo no son aplicables a otros dominios o a escenarios donde varios dominios diferentes deben usarse juntos. Además, a menudo los sistemas están diseñados para ser entrenados una vez a partir de un corpus y no permiten una mejora continua del conocimiento aprendido. Recientemente, hay intentos de construir sistemas de aprendizaje de propósito general que siempre mejoran mientras obtienen nuevos conocimientos, reevalúan los conocimientos antiguos y refinan su propia confianza~\cite{mitchell2015never}.

Además, es interesante diseñar sistemas de aprendizaje no monolíticos, sino que se construyen como un conjunto de componentes modulares que se pueden combinar de diferentes formas. Esta componibilidad permitiría un sistema de aprendizaje continuo no solo para mejorar la calidad del conocimiento extraído, sino también para aprender a sintonizar sus propios parámetros internos para realizar una mejor extracción de conocimiento en el futuro. Es concebible que dicho sistema pueda aprender gradualmente qué tipos de procesos básicos (es decir, reconocimiento de entidades, etiquetado POS, etc.) son más útiles para un dominio dado o para un corpus en particular. Asimismo, dicho sistema podría aprender qué tipos de modelos probabilísticos proporcionan los mejores resultados en un conjunto de datos en particular.

La velocidad y el volumen de producción de la información se ha incrementado exponencialmente en la última década, principalmente por el auge de las redes sociales y la tecnología móvil. Para hacer frente a este volumen de información, es necesario poder procesar cantidades masivas de datos de forma continua. El campo del aprendizaje automático proporciona herramientas para la extracción automática de información y conocimiento de diferentes fuentes de datos. El aprendizaje automático no solo permite automatizar procesos y tareas de descubrimiento de conocimiento o minería de textos, sino que también proporciona una gran mejora en la escalabilidad de estos procesos~\cite{wu2014data}. Mediante el uso de recursos informáticos masivos, es posible procesar millones de documentos sin procesar en un tiempo razonable, superando con creces lo que pueden hacer los expertos en el dominio. Las mejoras recientes en las capacidades informáticas y el acceso a conjuntos de datos más grandes han dado lugar al campo del aprendizaje profundo, que ha mejorado el estado del arte en varias de las tareas clásicas de aprendizaje automático~\cite{lecun2015deep}.

Podría decirse que los dos enfoques más comunes en el aprendizaje automático son el aprendizaje supervisado y no supervisado~\cite{kevin2012machine}. El aprendizaje supervisado se puede utilizar para reconocer elementos específicos de conocimiento en una fuente de datos. Por ejemplo, etiquetar fragmentos de texto para indicar que definen una entidad~\cite{nadeau2007survey} (p. Ej., Una persona, organización o lugar), reconocer relaciones entre dichas entidades o asignar un sentimiento o puntuación de opinión~\cite{liu2012sentiment} a un fragmento de texto. Por otro lado, el aprendizaje no supervisado puede ayudar a encontrar la estructura relevante en un gran conjunto de elementos. Los algoritmos de agrupación en clústeres se pueden utilizar para detectar conceptos similares o para extraer conceptos abstractos de grupos de elementos más concretos. Se pueden utilizar otras técnicas para reducir la cantidad de información, por ejemplo, para eliminar piezas de información ruidosas, inciertas o irrelevantes~\cite{bingham2001random}.

En general, la mayoría de los algoritmos de aprendizaje automático no están diseñados para representar el conocimiento aprendido en estructuras complejas, como las definidas por expertos en el dominio humano (es decir, ontologías). A su vez, las representaciones suelen tener una estructura simple, como una distribución de probabilidad o una matriz de correlación~\cite{bengio2013representation}. Al aplicar estos algoritmos a un problema real, se debe realizar una interpretación específica de dominio de esas representaciones.

Además, muchos de los modelos de aprendizaje automático más poderosos son difíciles de explicar, en el sentido de que cuando el sistema produce una respuesta, un experto humano no puede comprender y reproducir fácilmente los pasos de inferencia que realiza el sistema~\cite{olden2002illuminating}. La elección de una representación adecuada es decisiva para el éxito de la mayoría de las técnicas de aprendizaje automático~\cite{bengio2012deep}. En los últimos años, ha aumentado el interés en el problema del aprendizaje automático de representaciones relevantes. Las incrustaciones de palabras~\cite{mikolov} y las incrustaciones de entidades más generales~\cite{hu2015entity} representan los primeros pasos para impulsar los enfoques de aprendizaje profundo con representaciones internas más explicables. Dado que las ontologías son, por definición, representaciones de una conceptualización determinada, es concebible que utilizando ontologías como semillas para la representación de un dominio determinado, se pueda mejorar el rendimiento de los procesos de minería de datos basados en el aprendizaje automático.

\section{Entornos de Evaluación Competitivos}

Una estrategia que se utiliza a menudo para fomentar la investigación sobre una tarea específica es la organización de una campaña de evaluación compartida. En contraste con la investigación regular, las campañas de evaluación a menudo tienen un marco de tiempo fijo y los recursos de evaluación no se revelan completamente~(por ejemplo, las anotaciones de oro para los conjuntos de prueba están ocultas) para permitir una comparación justa en un entorno competitivo amigable. En esta sección, analizamos los esfuerzos relevantes para la organización de campañas de evaluación tanto del dominio biomédico como para el manejo de la extracción de entidades y relaciones.

Varios servicios en línea permiten a los investigadores organizar desafíos y concursos de aprendizaje automático, proporcionando calificación automática, administración de usuarios y otras funciones útiles. Kaggle\footnote{\url {https://kaggle.com}} es posiblemente la opción más popular, su principal limitación para nuestros propósitos es que para albergar un desafío, los organizadores deben comunicarse con los proveedores de servicios. Las posibles alternativas son AIcrowd\footnote{\url{https://www.aicrowd.com}} y Codalab\footnote{\url{https://codalab.org}}, que ofrecen opciones gratuitas para los organizadores del desafío.

El CLEF eHealth Evaluation Lab ha propuesto varios desafíos en el dominio biomédico, incluido el reconocimiento de entidades nombradas~\cite{clef2013} y la extracción de información~\cite{clef2014} en inglés, y ediciones posteriores en documentos franceses~\cite{clef2015, clef2016} . En estos desafíos, los informes médicos de MEDLINE, EMEA y fuentes similares se anotan con trastornos, términos médicos, acrónimos y abreviaturas, que proporcionan escenarios de evaluación para varias tareas de PNL, incluido el reconocimiento de entidades, la normalización y la desambiguación. Otra tarea relevante la propone ~ \ citet {semeval2017-task9} en Semeval 2017, centrada en el análisis sintáctico y la generación de AMR a partir de oraciones biomédicas en inglés. La aplicación de una conceptualización de propósito general, como AMR, a dominios específicos alentó a los participantes a cerrar la brecha entre el desarrollo de técnicas generalizables y la aplicación de heurísticas específicas de dominio. Sin embargo, el análisis sintáctico de la RAM ya es un problema complejo en sí mismo, que puede tener un impacto negativo en la participación de los investigadores en estos desafíos si no están especializados en la RAM. Los modelos más simples y de propósito general pueden fomentar un mayor grado de participación dada la curva de entrada más fácil. Un ejemplo de esto último es el Semeval 2017 Task 10~\cite{semeval2017-task10}, un desafío en cuanto a la extracción de frases clave y relaciones de documentos científicos, con un modelo simple basado en tres clases de entidades y dos relaciones de propósito general. Esta tarea recibió una cantidad mucho mayor de presentaciones que la anterior, aunque ambos desafíos se realizaron en el mismo lugar y estaban dirigidos a audiencias similares.

Como se puede esperar, el inglés es el idioma más utilizado en los desafíos relacionados con NER, dado el mayor número de corpus y recursos disponibles. Sin embargo, se han realizado importantes esfuerzos para fomentar la investigación en idiomas menos destacados. Son relevantes para nuestro debate las campañas de IberLEF que se centran en los idiomas ibéricos, como el español, el portugués, el catalán y otras variaciones regionales. Dos ejemplos de tareas recientes relacionadas con NER son el desafío portugués Entidad nombrada~\cite{glauber2019iberlef} y el desafío de anonimización de documentos MEDDOCAN~\cite{marimon2019automatic}. El primero propone el reconocimiento de entidades y la extracción de relaciones en el dominio general, en portugués. El segundo propone la identificación de menciones de entidades sensibles a la privacidad en documentos médicos, por ejemplo, nombres, direcciones, fechas, edades, etc.

Fuera del marco de una competencia, los sistemas de evaluación abiertos y de larga duración permiten a los investigadores evaluar sus enfoques con métricas de evaluación oficiales. Esto también puede proporcionar un repositorio centralizado del estado de la técnica, donde los enfoques existentes se resumen y se vinculan a los documentos existentes. En este sentido, esta investigación propone un sistema de evaluación en línea que permite comparar los nuevos enfoques con los resultados publicados oficialmente en cualquier momento. A partir de esta infraestructura, se organizan campañas de evaluación oficiales con un diseño más competitivo en plazos programados.

\section{Representación del Conocimiento}

Hay muchos recursos que se utilizan en la tarea del procesamiento del lenguaje natural. Entre las más comunes, las ontologías, como representaciones de conceptos, tipos de datos y sus relaciones en una estructura computacional explícita. Algunas de las ontologías más populares utilizadas en PNL son WordNet~\cite{} y DBpedia~\cite{}. Por su ubicuidad y utilidad, la investigación en ontologías se ha incrementado en los últimos años, particularmente en lo que respecta a la creación automática de estas estructuras, dando origen al campo del Aprendizaje Ontológico. El aprendizaje de ontologías tiene el potencial de reducir el costo de crear y, lo que es más importante, mantener ontologías grandes y complejas~\cite{cimiano2009ontology}.

El aprendizaje de ontologías se ocupa del problema de crear automáticamente una ontología a partir de varios recursos. Los ejemplos incluyen análisis de minería, principalmente
el estudio de texto en lenguaje natural~\cite{}. En esta tarea en particular, se han presentado varios enfoques, desde el análisis sintáctico y semántico de corpora~\cite{} hasta enfoques estadísticos y basados   en el aprendizaje automático~\cite{}.

Se han propuesto varias herramientas y sistemas para esta tarea. Text2Onto~\cite{cimiano2005text2onto} es un marco para el descubrimiento de cambios impulsado por datos que emplea un modelo de ontología probabilística (POM).
OntoLT~\cite{buitelaar2004ontolt} extrae conceptos y relaciones automáticamente de colecciones de texto anotadas lingüísticamente, por medio de un conjunto de reglas, que asigna clases lingüísticas a clases de ontología.
Un enfoque más nuevo es OntoGain~\cite{drymonas2010unsupervised}, que utiliza un enfoque no supervisado y explota la información léxica inherente del término de varias palabras para extraer conceptos de nivel superior.

Uno de los problemas con estos enfoques es la cantidad de información falsa que generan~\cite{Maimon:2015:OLT:2870689.2870690}. En general, habrá muchas piezas de información redundantes o sin importancia en los corpus analizados. Un enfoque ingenuo que no tenga en cuenta este tema creará ontologías inmensas con muy poca información útil. Para abordar este problema, OntoGain propone un esquema de agrupamiento jerárquico que intenta identificar conceptos y relaciones generales.

En general estos recursos están enfocados en la extracción de conocimiento y prestan mucha menos atención a la tarea de encontrar conocimiento relevante. Una ontología es interesante no solo por su tamaño, sino también por cómo se selecciona, procesa y almacena dicha información. En esta problemática enfocamos nuestro trabajo, intentando no solo reconocer información, sino también reducir esta información y obtener información con más relevancia.

El problema de descubrir, almacenar y utilizar el conocimiento en una forma computacionalmente eficaz ha sido ampliamente estudiado~\cite{mitchell2015never, ROSPOCHER2016132, cimiano2009ontology}. Este problema ha sido tratado desde dos áreas de investigación distintas pero complementarias: los campos de representación del conocimiento y aprendizaje automático. La comunidad de representación del conocimiento proporciona medios para representar y operar computacionalmente con el conocimiento almacenado en formas que pueden asegurar cierto grado de consistencia lógica. Por el contrario, la comunidad de aprendizaje automático proporciona herramientas para obtener conocimientos útiles a partir de grandes colecciones de datos estructurados y no estructurados. Recientemente, ha surgido una nueva disciplina llamada aprendizaje de ontologías, que extrae ideas y técnicas tanto de la representación del conocimiento como de los campos del aprendizaje automático. Este campo se ocupa del problema de construir automáticamente representaciones ontológicas del conocimiento a partir de una variedad de fuentes de datos. Como tal, la teoría del aprendizaje de la ontología es relevante en el diseño del marco presentado en este artículo. En esta sección presentamos una breve revisión de los conceptos y tecnologías relevantes en cada uno de estos tres dominios, así como algunos enfoques similares a nuestra propuesta.

\subsection{Knowledge Representation and Reasoning}

Desde los albores de la informática, uno de los problemas que ha atraído gran atención es el de representar el conocimiento en un formato computacional, de modo que se pueda realizar un razonamiento automático para descubrir verdades nuevas, previamente desconocidas~\cite{sowa2000knowledge}. Podría decirse que la tecnología de representación del conocimiento más popular en uso son las ontologías~\cite{guarino1995formal}, que se han convertido en el estándar \ emph {de facto}.
Las ontologías se pueden definir como una especificación formal de una conceptualización~\cite{asuncion2003}. Esto representa conceptos, relaciones entre estos conceptos, instancias de estos conceptos y reglas de inferencia para derivar nuevas relaciones.

Como tales, las ontologías pueden considerarse como una combinación de dos enfoques predominantes para la representación del conocimiento: los basados en la lógica formal~\cite{brachman1992knowledge} y los basados en gráficos de relaciones semánticas~\cite{chein2008graph}. En los enfoques basados en la lógica, los hechos se representan como predicados o funciones lógicas y el razonamiento se habilita mediante la aplicación de reglas formales de inferencia.
Por el contrario, las representaciones basadas en gráficos expresan hechos como nodos~(objetos) y aristas~(relaciones) y el razonamiento se basa en los métodos de desplazamiento de gráficos. Sin embargo, en las ontologías, los objetos y sus atributos y relaciones se representan en un gráfico de conceptos, que también se puede interpretar como un conjunto de predicados y funciones sobre estos objetos. Además de esta capa, se pueden agregar reglas de inferencia, que permiten utilizar métodos de razonamiento lógico para derivar nuevos atributos y relaciones entre conceptos existentes.

Las relaciones en una ontología pueden ser de un dominio específico, pero a menudo se representan algunas relaciones de dominio generales, como \textit{es-a} y \textit{parte-de}. Este tipo de relaciones permiten representar conceptos más abstractos o complejos a partir de la composición de conceptos más concretos o simples. Por tanto, muchas ontologías contienen algún tipo de taxonomía de conceptos cada vez más abstractos, que también están interconectados entre sí utilizando otras relaciones semánticas que pueden ser específicas de dominio.
Estos recursos permiten representar marcos de conocimiento complejos, hasta un grado de especificidad que permite el diseño de herramientas de razonamiento totalmente automatizadas que utilizan este conocimiento para una variedad de tareas computacionales.
Debido a la alta complejidad de los conceptos y relaciones que se representan, y la experiencia necesaria para reconocer los conceptos más relevantes de un dominio, las ontologías suelen ser construidas manualmente por expertos en el dominio~\cite{wong2012ontology}. Así, construir una ontología es un proceso que requiere mucho tiempo y una gran cantidad de expertos para definirlo y poblarlo con instancias relevantes que se refieren a objetos y relaciones. Esto hace realmente difícil construir ontologías artesanales y asegurar su mantenibilidad, debido a que día a día aparece en la World Wide Web una gran cantidad de información nueva y valiosa, deseable para convertirla en conocimiento. Otro resultado importante de este proceso es que los expertos generalmente representan solo hechos que son absolutamente ciertos en el dominio. Aunque los formatos de ontología existentes pueden extenderse para tratar con~\cite{fuzzyontology} difusos o datos vagos~\cite{bobillo2011fuzzy}, asignar manualmente un grado de creencia a un hecho específico es una tarea compleja.

Es posible distinguir entre dos tipos de ontologías: dominios generales (u ontologías superiores) y dominios específicos (o simplemente ontologías de dominios). Las ontologías específicas de dominio son aquellas que se ocupan de los conceptos y relaciones del dominio de conocimiento particular. Como ejemplos, podemos citar ontologías en las ciencias médicas~\cite{rector2003opengalen, gene2004gene}, o el campo de la ingeniería de software~\cite{4641930}. Otras ontologías son más generales, ya que pueden usarse en diferentes dominios, o se usan para tareas de propósito general que se emplean en muchas áreas. WordNet~\cite{miller1995wordnet} es una ontología de propósito general que contiene la mayoría de las palabras del idioma inglés y las relaciones sintácticas y semánticas entre ellas. Se utiliza en muchas tareas de procesamiento de lenguaje natural y minería de texto. DBPedia~\cite{mendes2012dbpedia} es una ontología enciclopédica que contiene parte del conocimiento presente en Wikipedia\footnote{http://www.wikipedia.org}. Relaciona personas, eventos históricos, hechos, ubicaciones y otros conceptos, en un formato estructurado y consultable. Dado que las ontologías tienen una forma unificada de representar un solo hecho, concepto o relación utilizando el Localizador Uniforme de Recursos ~ (URL), es posible y muy común que diferentes ontologías se vinculen entre sí. Por ejemplo, muchas ontologías específicas de dominio tienen entidades que están vinculadas a la entrada correspondiente en DBPedia. El enfoque de vincular y referenciar a otras ontologías ampliamente conocidas, conocido como \ textit {link data}~\cite{bizer2009linked}, permite estandarizar la representación del conocimiento compartido y facilita las tareas de consulta y análisis.

Las ontologías son una herramienta eficaz para representar el conocimiento en una amplia variedad de dominios y escenarios~\cite{staab2010handbook}. Son lo suficientemente flexibles para adaptarse a un dominio particular y lo suficientemente potentes como para representar conceptos complejos. Sin embargo, una de las tareas más complejas en este sentido es mantener una ontología actualizada con respecto a la masiva cantidad de datos no estructurados que se generan y publican todos los días. Por tanto, surge la necesidad de herramientas computacionales para construir ontologías con procesos automatizados o semiautomatizados.

\subsection{Ontology Learning}

En la intersección del aprendizaje automático y la representación del conocimiento, ha surgido el campo del aprendizaje de ontologías para lidiar con la complejidad de mantener y actualizar ontologías manualmente. Este campo extrae técnicas y herramientas de ambas comunidades, para automatizar parte del proceso de creación y mantenimiento de ontologías. El aprendizaje de la ontología tiene el potencial de reducir el costo de crear y, lo que es más importante, mantener ontologías grandes y complejas~\cite{cimiano2009ontology}. Este problema también se aborda en el aprendizaje mediante la lectura~\cite{barker2007learning}, un campo en el que se extraen técnicas del procesamiento del lenguaje natural y las comunidades de representación y razonamiento del conocimiento. El propósito es construir una representación formal de algún campo en particular dados datos textuales sin restricciones relacionados con el campo. Esta representación también debe permitir un razonamiento completamente automático. El aprendizaje mediante la lectura se puede considerar como un caso particular de aprendizaje de ontología, aunque solo se refiere a la entrada textual, y la salida no está necesariamente formateada como una ontología.

En el campo del aprendizaje de la ontología, se pueden distinguir dos tareas generales de alto nivel: población de ontología y enriquecimiento de ontología~\cite{petasis2011ontology}. La población de ontologías se ocupa del subproblema de encontrar nuevas instancias para una ontología ya definida, mientras que el enriquecimiento de ontologías se ocupa de agregar nuevos conceptos y relaciones a una ontología existente. Existe una superposición entre estas tareas y la mayoría de los enfoques existentes no pueden clasificarse únicamente en estos términos. En este campo, se han propuesto varias herramientas, que combinan diferentes enfoques y resuelven diferentes subconjuntos de las tareas de aprendizaje de la ontología. Una breve revisión de estos sistemas puede ayudar a definir las principales características que debe tener nuestro framework.

Los primeros enfoques, como SYNDIKATE~\cite{syndikate}, tratan solo de poblar una base de conocimiento, con una estructura ontológica predefinida~(clases y relaciones). Dado que la Web es una rica fuente de información, varios enfoques se han centrado en extraer conocimiento de ella, explotando el formato semiestructurado de los recursos web. Algunos sistemas como ARTEQUAKT~\cite{artequakt} y SOBA~\cite{soba} son de dominio específico, centrándose respectivamente en el arte y los dominios deportivos. Otros sistemas, como WEB - $> $ KB~\cite{webkb} intentan construir bases de conocimiento de dominio general desde la web, explotando también la estructura de enlaces entre páginas para identificar relaciones. Otro ejemplo es el sistema VIKEF~\cite{vikef}, que utiliza catálogos de productos como fuentes de datos, aprovechando así la estructura inherente presente en este tipo de datos. Aunque la mayoría de los sistemas intentan una extracción completamente automática, algunos ejemplos como ADAPTATIVA~\cite{adaptativa} incluyen una estrategia de arranque, donde los expertos humanos brindan retroalimentación sobre el conocimiento extraído.

Para extraer el conocimiento relevante de un texto sin restricciones, se han introducido técnicas de PNL en sistemas como OPTIMA~\cite{optima} e ISODLE~\cite{isolde}. El uso de características del lenguaje natural puede usarse para construir sistemas basados   en reglas, como la propuesta OntoLT~\cite{buitelaar2004ontolt}, que extrae conceptos y relaciones a través de un mapeo de clases lingüísticas a clases de ontología. Un enfoque alternativo es utilizar modelos estadísticos o probabilísticos, ejemplificados por sistemas como LEILA~\cite{leila} o Text2Onto~\cite{cimiano2005text2onto}. Otro ejemplo es KnowItAll~\cite{knowitall}, que introduce una métrica de información mutua puntual para seleccionar instancias relevantes.

Una vez que las instancias de entidades son relaciones se extraen del texto, una pregunta natural es si se puede inferir un conocimiento más abstracto de estos ejemplos. Los sistemas que abordan este problema a menudo utilizan técnicas no supervisadas para intentar descubrir estructuras inherentes. Dos ejemplos relevantes de este enfoque son OntoGain~\cite{drymonas2010unsupervised} y ASIUM~\cite{asium}, que intentan construir automáticamente una jerarquía de conceptos usando técnicas de agrupamiento. El sistema BOEMIE~\cite{boemie} es otro ejemplo interesante, ya que intenta inferir automáticamente conceptos abstractos de las instancias concretas encontradas, pero se centra no solo en el texto, sino también en fuentes multimedia como imágenes y videos. La mayoría de los sistemas mencionados generalmente se enfocan en una iteración del proceso de extracción. Sin embargo, los enfoques más recientes, como NELL~\cite{mitchell2015never}, intentan aprender continuamente de un flujo de datos web y aumentan con el tiempo tanto la cantidad como la calidad del conocimiento descubierto.

Uno de los problemas con muchos de estos enfoques es la cantidad de información falsa que generan~\cite{Maimon:2015:OLT:2870689.2870690}. En general, habrá muchas piezas de información redundantes o sin importancia en los corpus analizados. Un enfoque ingenuo que no tenga en cuenta este tema creará ontologías inmensas con muy poca información útil. Para abordar este problema, OntoGain propone un esquema de agrupamiento jerárquico que intenta identificar conceptos y relaciones generales.

En general, estas herramientas están enfocadas a la extracción de conocimiento y a la tarea de encontrar conocimiento relevante. Cuando se extrae conocimiento de una fuente confiable, incluso si es una fuente de lenguaje natural, tiene sentido enfocarse en optimizar el recuerdo, es decir, obtener la mayor cantidad de información posible. Si la fuente de entrada es un conjunto de artículos médicos o la página web principal de una institución, existe una alta probabilidad de que la mayor parte de la información presente en esos documentos sea correcta. Por lo tanto, un procedimiento de extracción de ontología que maximice el recuerdo obtendrá buenos resultados.

Sin embargo, cuando la fuente de entrada es de menor calidad, como blogs o publicaciones en redes sociales, existe una mayor probabilidad de que parte, o incluso la mayoría, de la información sea falsa o incorrecta. Si consideramos también los llamados fenómenos de la \textit{posverdad}, y reconocemos que algunos autores comparten deliberadamente noticias o hechos falsos, el problema se vuelve mucho más difícil y urgente. Incluso si las mentiras deliberadas no fueran un problema, la mayor parte de la información compartida en las redes sociales y fuentes similares es irrelevante a largo plazo. En este contexto, el problema de extraer una ontología útil de un gran corpus de fuentes de Internet se vuelve menos un problema de reconocimiento de las piezas de información que se encuentran en el corpus, y más un problema de filtrado y selección de la información relevante, una vez extraída.

A pesar de la existencia de algunos sistemas de propósito general, no existe una propuesta de arquitectura para un marco computacional que pueda aprender de manera simultánea y continua de las más variadas fuentes de información en línea. Otro desafío en este aspecto es obtener una representación computacionalmente conveniente de este conocimiento, independientemente del dominio, fuente y formato de los datos de entrada. Además, dicho sistema tiene que lidiar explícitamente con la gran cantidad de información falsa, irrelevante o deliberadamente falsa que se difunde a través de fuentes web.

\subsection{Quality Metrics}\label{sec: evaluación}

En esta sección presentamos una metodología para evaluar dicho marco y obtener métricas interesantes que pueden validar su desempeño en la amplia gama de tareas que el marco pretende habilitar.

En un sistema computacional o marco de software, hay métricas de ingeniería de software interesantes para evaluar.
Dicho sistema debe ser altamente modular y extensible, de modo que pueda adaptarse fácilmente a los nuevos formatos de entrada, o los nuevos algoritmos se pueden conectar e integrar fácilmente en toda la tubería.
El diseño modular del marco puede ayudar a lograr un alto grado de extensibilidad.

Además de estas métricas de alto nivel, cada una de las tareas realizadas por el marco se puede evaluar por separado.
La mayoría de estas tareas tienen una métrica de rendimiento definida que se puede utilizar para evaluar el grado de corrección de dicha tarea.
Para muchas de las tareas descritas en las secciones anteriores, podemos encontrar métricas de desempeño estándar en la literatura que pueden usarse para evaluar cada proceso en particular.

Una métrica agregada de estos desempeños individuales podría proporcionar una descripción general de alto nivel del desempeño de todo el marco.
Sin embargo, diseñar una métrica agregada que proporcione una medida práctica e interpretable de la calidad del desempeño del marco puede ser muy complejo.
Cada una de las diferentes tareas realizadas por el marco puede tener un rendimiento de referencia muy diferente.
Una precisión del 90\% puede ser un muy buen resultado en algunas tareas complejas, como el análisis de dependencias~\cite{AlbertiABCGKKMO17}, pero mediocre en otras tareas, como la clasificación de imágenes~\cite{Russakovsky2015}.
Además, este número de referencia puede variar no solo entre las tareas, sino también en la misma tarea, según el conjunto de pruebas (o corpus)
se utiliza.

Subiendo un nivel de abstracción, para el problema general del aprendizaje de la ontología, también hay varias métricas y metodologías de evaluación disponibles, como OntoRand~\cite{ontorand} y OntoMetric~\cite{ontometric}.
Sin embargo, la mayoría de estas metodologías están diseñadas para evaluar una sola ontología que se crea o modifica utilizando técnicas de aprendizaje de ontologías.
Una vez más, extender estas metodologías a una colección de ontologías no es tan sencillo como agregar o promediar los resultados individuales.
Por otro lado, cuando se trata de una colección de ontologías, pueden surgir otras inquietudes, como la consistencia intra-ontológica, que no suelen considerarse al evaluar una única ontología.
Presentamos algunos de los enfoques más comúnmente descritos en la literatura para evaluar ontologías~\cite{petasis2011ontology} y describimos cómo pueden usarse en nuestro contexto.

\paragraph{M1- Comparación con un patrón oro.}

Este enfoque consiste en comparar una ontología aprendida con una ontología de referencia para el mismo dominio~\cite{corcoglioniti2016frame}.
Se supone que la ontología de la línea de base es correcta y en gran medida representativa del dominio.
Este método proporciona una gran compensación entre velocidad y precisión, ya que ambas ontologías se pueden comparar automáticamente en una serie de métricas sin intervención humana, y los resultados tienen una alta confiabilidad porque la ontología de referencia es creada por expertos.
Existen algunas desventajas, por ejemplo, no siempre es fácil encontrar una buena ontología de base para un dominio dado, especialmente si el dominio no está muy bien definido o es muy novedoso.
Por otro lado, incluso dos ontologías extraídas del mismo dominio por expertos pueden tener grandes diferencias con respecto a la estructura y, en particular, a los nombres que se asignan a las clases y relaciones.
Esto requiere alguna forma de normalización y mapeo entre ambas ontologías antes de la comparación.
Esta métrica es difícil de usar, especialmente si estamos creando nuevas características.

\paragraph{M2- Evaluación experta.}

Un término medio alternativo al enfoque anterior es tener un experto en el dominio (o varios) para simplemente mirar la ontología resultante y evaluarla de acuerdo con algunas métricas predefinidas~\cite{ROSPOCHER2016132}.
Este es posiblemente el método más confiable, en el sentido de que proporciona el mayor grado de validación que uno podría aspirar.
Sin embargo, la clara desventaja radica en la cantidad limitada de información que un ser humano puede procesar en un tiempo razonable.
Esta desventaja se agrava en el caso en que se crea una ontología a partir de un corpus de datos muy grande, como es el propósito de nuestro marco.
En este caso, se podría analizar un pequeño subconjunto de los datos y extrapolar los resultados desde allí, pero esta idea agrega la complejidad de determinar un subconjunto que es lo suficientemente relevante pero que sigue siendo de un tamaño manejable.
Esta métrica suele ser cara o difícil de usar.

\paragraph{M3- Evaluación a través de una aplicación.}

Un enfoque más práctico consiste en encontrar una aplicación interesante y evaluar si el uso de una ontología aprendida proporciona una mejora en esa aplicación~\cite{gurevych2003semantic}.
Por ejemplo, usar una ontología aprendida sobre sentimientos humanos y frases relacionadas para mejorar el desempeño de un problema estándar de minería de opiniones.
Si el uso del conocimiento representado en la ontología proporciona un impulso al rendimiento, medido por el enfoque estándar en la aplicación dada, obtenemos una validación confiable de que el proceso para aprender ontología, al menos, tiene un beneficio práctico medible.
En cierto sentido, esta es una de las evaluaciones más valiosas para realizar, porque proporciona una línea base de comparación inmediata para un problema práctico.
Los métodos anteriores que solo evalúan la ontología internamente no garantizan necesariamente que su contenido sea útil, incluso si es correcto según todas las métricas.
Otra ventaja es que el proceso de evaluación se puede automatizar por completo y escalar para que coincida con la complejidad y el tamaño de la aplicación de destino.
Como desventaja, validar un caso de uso no es necesariamente una métrica de la calidad general del conocimiento aprendido, y no está claro si esos resultados se replicarán en diferentes dominios y aplicaciones.
Esta métrica de hecho parece más simple pero en muchos casos no es necesario mejorar una tarea, sino un conjunto amplio.

\paragraph{M4- Evaluación basada en datos.}

Finalmente, se puede realizar una evaluación basada en datos, comparando las entidades y relaciones en una ontología con un corpus de datos, no usados   durante la construcción de la ontología, pero representativos del mismo dominio~\cite{brank2005survey}.
La ontología se puede evaluar contando el número de entidades superpuestas presentes en ella con las que se encuentran en el corpus.
Se debe tener cuidado para permitir alguna variación en el corpus con respecto a la ontología, por ejemplo, usando alguna forma de expansión de consultas.
Este enfoque se ha utilizado para comparar relativamente diferentes ontologías creadas por expertos con el mismo corpus y decidir qué ontología proporciona el mejor `` ajuste '' con el corpus~\cite{brewster2004data}.
Sin embargo, obtener una métrica absoluta de ajuste entre una ontología y un corpus es más difícil, principalmente porque no se sabe de antemano cuál es el valor de ajuste que uno debería esperar lograr.
Otro posible problema de este enfoque, en el caso particular de las ontologías que se han aprendido del texto, es introducir inadvertidamente un sesgo en la evaluación.
Si los métodos utilizados para comparar la ontología y el corpus de texto están correlacionados con los utilizados para construir la ontología, entonces los resultados serán de dudosa validez.
Por ejemplo, si se usa un algoritmo NER durante la construcción de la ontología, y se usa el mismo algoritmo en el corpus para reconocer entidades relevantes; o si se usa alguna métrica de co-ocurrencia para detectar relaciones en ambos casos.
Esta métrica es compleja de definir y en muchas ocasiones no es representativa.

\vspace{1em}

Evaluar un solo método de aprendizaje de ontología es una tarea compleja, como lo demuestran los múltiples enfoques propuestos en la comunidad.
Por lo tanto, es muy poco probable que podamos encontrar una única métrica automatizada para medir el rendimiento general de un marco como el propuesto.
El mejor enfoque parece ser utilizar una combinación de los métodos existentes, adaptados a nuestro escenario, con la complejidad añadida de tratar con múltiples ontologías al mismo tiempo.
En algunos casos, se puede encontrar un patrón oro y utilizarlo para obtener una comparación de referencia.
En otros casos, siempre que se agregue una interfaz adecuada para consultar fácilmente el conocimiento, un experto en el dominio puede interactuar con el marco y dar una evaluación cualitativa para el dominio de interés.
Desde un punto de vista pragmático, la evaluación más interesante y valiosa parece ser encontrar problemas prácticos relevantes que se puedan resolver o mejorar al utilizar nuestro marco.

\subsection{Discusión de las tareas de aprendizaje}

En la comunidad de aprendizaje de ontología, se han desarrollado varios marcos que atacan problemas similares a los que presentamos.
Algunos de los enfoques encontrados en la literatura se concentran en una tarea en particular, es decir, creación, población o enriquecimiento de ontologías, entre otras.
Por ejemplo, marcos como KnowItAll~\cite{knowitall}, Artequakt~\cite{artequakt} y SOBA~\cite{soba} están orientados principalmente hacia la tarea de población de ontologías.
Otros, como ASIUM~\cite{asium}, VIKEF~\cite{vikef} y SYNDICATE~\cite{syndikate} están orientados principalmente al enriquecimiento de ontologías.
Sin embargo, muchas de las tareas o subproblemas que deben resolverse en cualquiera de estos dominios son muy similares y pueden reutilizarse.
Por lo tanto, han surgido marcos más generales como Text2Onto~\cite{cimiano2005text2onto} o BOEMIE~\cite{boemie} que tratan con una combinación de estas tareas.

\subsection{Cantidad y complejidad}

En cuanto a la cantidad y complejidad de conceptos reconocidos, las soluciones existentes se pueden dividir en aquellas que solo extraen entidades (ej., KnowItAll), aquellas que solo extraen relaciones (ej., ADAPTATIVA~\cite{adaptativa}, LEILA~\cite{leila}) y aquellos que intentan extraer ambos (por ejemplo, Artequakt, Web-> KB~\cite{webkb}, BOEMIE).
El descubrimiento de reglas de inferencia es otra tarea relevante que enriquece las ontologías ya construidas al agregar conocimientos de nivel superior, en forma de predicados lógicos o axiomas.
Estos, a su vez, pueden usarse más adelante para descubrir instancias o relaciones faltantes, o para detectar valores atípicos y errores.

\subsection{Uso del aprendizaje automático}

La mayoría de los sistemas emplean algún tipo de herramientas de aprendizaje automático para la mayoría de las tareas. En particular, muchos emplean herramientas de PNL para procesar texto natural y extraer conocimientos, y técnicas estadísticas para detectar agrupaciones.
Sin embargo, en general, la arquitectura de estos sistemas generalmente sigue una tubería diseñada muy estrictamente, donde los componentes se conectan cuidadosamente entre sí.

\subsection{Entrada humana}

La mayoría de los marcos y soluciones existentes requieren un cierto grado de interacción humana. En la mayoría de los casos, se espera que un experto en el dominio interactúe con una herramienta computacional para validar o refinar el resultado del proceso de aprendizaje.
Sin embargo, esta posibilidad de interacción es un resultado del marco, no una necesidad.

\subsection{Generalización}

Con respecto a las restricciones de dominio, podemos clasificar las soluciones existentes en aquellas que son completamente independientes del dominio (por ejemplo, KnowItAll, LEILA, ISOLDE~\cite{isolde}) y aquellas que están adaptadas
a dominios particulares (por ejemplo, SOBA, Artequakt). Las soluciones independientes del dominio generalmente se diseñan de manera que no haya una dependencia particular ligada a un dominio, por lo tanto, son reutilizables en varios dominios. Sin embargo, esto significa que un sistema puede usarse en un dominio u otro, pero no significa necesariamente que el mismo sistema pueda aprender un poco de conocimiento de dos dominios diferentes \emph{simultáneamente}.

Si un sistema está simplemente diseñado para ser independiente del dominio y se utiliza para aprender de dos dominios muy diferentes, el resultado esperado es una especie de ontología combinada que representa ambos dominios con una aproximación de la unión de los conceptos (entidades y relaciones) en ellos. . Esta puede no ser la representación ideal, especialmente cuando se extiende a muchos dominios diferentes. Tratando de construir una ontología única que abarque todo el conocimiento que se puede extraer de
varios dominios diferentes (posibles en el orden de cientos o miles) pueden ser significativamente más difíciles que una simple suma o unión de cada uno de los dominios individuales.

Es cierto que los humanos tenemos un conjunto básico de habilidades que podrían considerarse independientes del dominio, como nuestras habilidades innatas para la coincidencia de patrones. Estas habilidades básicas se utilizan en muchas de las tareas con las que nos enfrentamos a diario.
La analogía computacional es un sistema con un único algoritmo de aprendizaje de propósito general que podría realizar, por ejemplo, tareas tan diferentes como el reconocimiento de voz, la clasificación de imágenes y la traducción con el mismo proceso.
Este es el enfoque preferido por una parte de la comunidad de investigadores en aprendizaje automático~\cite{kaiser2017one},
que esperan construir una inteligencia de propósito general a partir de un solo algoritmo de aprendizaje de propósito general y una única representación interna de propósito general.

Sin embargo, para tareas realmente complejas, argumentamos que los humanos usan representaciones especializadas, algoritmos de aprendizaje y técnicas de inferencia. Un experto humano en un dominio altamente complejo (como las matemáticas), no utiliza las mismas técnicas para la inferencia que las que se utilizan en tareas en tiempo real como el reconocimiento de objetos y de voz. Reconocemos que la inferencia en dominios muy complejos no se puede realizar con herramientas basadas en la intuición. La construcción de un sistema inteligente que pueda realizar inferencias en varios dominios altamente complejos simultáneamente requerirá el uso de representaciones y técnicas especializadas en cada dominio. Es hacia este principio que guiamos nuestras decisiones de diseño.

\section{Discusión}
